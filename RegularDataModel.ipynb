{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegularDataModel.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this python notebooks, we train 3 models as per the paper.\n",
        "\n",
        "1. Bag Of tricks\n",
        "2. CNN Model\n",
        "3. CNN 3 layer architecture.\n",
        "\n",
        "These models are used for 'regular' ICM codes as outputs. \n",
        "\n",
        "More details can be found in the paper."
      ],
      "metadata": {
        "id": "fuqV4CDgDS1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attach Google Drive"
      ],
      "metadata": {
        "id": "B4vUsJQqDx7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhZqYA0g3lca",
        "outputId": "42e9c9b9-ef44-4f8b-cbf2-67f25462c744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data',\n",
              " 'BOTKeras.ipynb',\n",
              " 'CNNModel.ipynb',\n",
              " 'CNN3Layer.ipynb',\n",
              " 'Reference',\n",
              " 'storedModels',\n",
              " '.ipynb_checkpoints',\n",
              " 'Preprocess.ipynb',\n",
              " 'BOTModel.ipynb',\n",
              " 'RegularYModelReference.ipynb',\n",
              " 'BOTModelReference.ipynb',\n",
              " 'OriginalModelRolledData.ipynb',\n",
              " 'OriginalModelRegularData.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "mypath = \"drive/My Drive/CS598DLHProject\"\n",
        "os.listdir(mypath)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the data\n"
      ],
      "metadata": {
        "id": "q8zuXUJ6AvmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Already unzipped. Not required\n",
        "\n",
        "# !unzip drive/My\\ Drive/CS598DLHProject/data/original_paper_data/data.npz.zip -d drive/My\\ Drive/CS598DLHProject/data/original_paper_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxxK1Msd7_8m",
        "outputId": "f4acb25d-a966-4e09-e8bb-cf00d97f72eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/My Drive/CS598DLHProject/data/original_paper_data/data.npz.zip\n",
            "  inflating: drive/My Drive/CS598DLHProject/data/original_paper_data/data.npz  \n",
            "  inflating: drive/My Drive/CS598DLHProject/data/original_paper_data/__MACOSX/._data.npz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the model into relevant attributes. (X, Y_rolled, Y_regular and categories.)"
      ],
      "metadata": {
        "id": "ltW2mdQ6A05J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to convert input data data.npz into x,cats,rolled,regular but not required now\n",
        "\n",
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}data.npz'\n",
        "\n",
        "# print ('reading from saved file Data.npz: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "#     # print(data[item])\n",
        "\n",
        "# print(\"done\")\n",
        "# x = data['x']\n",
        "# cats = data['cats']\n",
        "# y_rolled = data['rol_y']\n",
        "# y_full = data['reg_y']\n",
        "\n",
        "# print(x.shape)\n",
        "# print(cats.shape)\n",
        "# print(y_rolled.shape)\n",
        "# print(y_full.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtkpylYD4LpV",
        "outputId": "0eb3226a-4a11-4d42-943d-2f75a9ea9fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file Data.npz:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/data.npz\n",
            "x\n",
            "cats\n",
            "reg_y\n",
            "rol_y\n",
            "done\n",
            "(399623, 2199)\n",
            "(399623, 15)\n",
            "(399623, 781)\n",
            "(399623, 4103)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribute the data into Train/Test/Validation data and save the data\n",
        "\n"
      ],
      "metadata": {
        "id": "f1fGlsnZA_Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporary block to convert data.npz into train/val/test\n",
        "\n",
        "# texts = x\n",
        "# texts_categories = cats\n",
        "# regular_labels = y_full\n",
        "# rolled_labels = y_rolled\n",
        "\n",
        "# # Split\n",
        "# s1 = int(.64 * len(texts))\n",
        "# s2 = int(.8 * len(texts))\n",
        "# x_train, x_val, x_test = np.split(texts, [s1, s2])\n",
        "# cats_train, cats_val, cats_test = np.split(texts_categories, [s1, s2])\n",
        "# reg_y_train, reg_y_val, reg_y_test = np.split(regular_labels, [s1, s2])\n",
        "# rol_y_train, rol_y_val, rol_y_test = np.split(rolled_labels, [s1, s2])\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTest.npz',\n",
        "#           x_train=x_train, x_val=x_val, x_test=x_test,\n",
        "#           cats_train=cats_train, cats_val=cats_val, cats_test=cats_test,\n",
        "#           reg_y_train=reg_y_train, reg_y_val=reg_y_val, reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train, rol_y_val=rol_y_val, rol_y_test=rol_y_test)"
      ],
      "metadata": {
        "id": "fY_ebvGIDCUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide dataset into 5 parts\n",
        "\n",
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTest.npz'\n",
        "\n",
        "# print ('reading from saved file dataTrainValTest.npz: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "\n",
        "# x_train = data['x_train']\n",
        "# x_val = data['x_val']\n",
        "# x_test = data['x_test']\n",
        "\n",
        "# rol_y_train = data['rol_y_train']\n",
        "# rol_y_val = data['rol_y_val']\n",
        "# rol_y_test = data['rol_y_test']\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# reg_y_test = data['reg_y_test']\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# print('x_test: ', x_test.shape)\n",
        "\n",
        "# print('rol_y_train: ', rol_y_train.shape)\n",
        "# print('rol_y_val: ', rol_y_val.shape)\n",
        "# print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# print('y_train: ', reg_y_train.shape)\n",
        "# print('y_val: ', reg_y_val.shape)\n",
        "# print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# total_values = 399623\n",
        "# total_values_val = 63940\n",
        "# i = 0\n",
        "# ratio = 0.2\n",
        "\n",
        "# print (\"Storing results for train - i=\" + str(i) + \" - \" + str(int(i*ratio*total_values)) + \" to \" + str(int((i+1)*ratio*total_values)))\n",
        "# print (\"Storing results for test i=\" + str(i) + \" - \" + str(int(i*ratio*total_values_val)) + \" to \" + str(int((i+1)*ratio*total_values_val)))\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTestSet1.npz',\n",
        "#           x_train=x_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           x_val=x_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           x_test=x_test,\n",
        "#           reg_y_train=reg_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           reg_y_val=reg_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           rol_y_val=rol_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           rol_y_test=rol_y_test)\n",
        "\n",
        "# i = i + 1\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values)) + \" to \" + str(int((i+1)*ratio*total_values)))\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values_val)) + \" to \" + str(int((i+1)*ratio*total_values_val)))\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTestSet2.npz',\n",
        "#           x_train=x_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           x_val=x_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           x_test=x_test,\n",
        "#           reg_y_train=reg_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           reg_y_val=reg_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           rol_y_val=rol_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           rol_y_test=rol_y_test)\n",
        "\n",
        "# i = i + 1\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values)) + \" to \" + str(int((i+1)*ratio*total_values)))\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values_val)) + \" to \" + str(int((i+1)*ratio*total_values_val)))\n",
        "\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTestSet3.npz',\n",
        "#           x_train=x_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           x_val=x_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           x_test=x_test,\n",
        "#           reg_y_train=reg_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           reg_y_val=reg_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           rol_y_val=rol_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           rol_y_test=rol_y_test)\n",
        "\n",
        "# i = i + 1\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values)) + \" to \" + str(int((i+1)*ratio*total_values)))\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values_val)) + \" to \" + str(int((i+1)*ratio*total_values_val)))\n",
        "\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTestSet4.npz',\n",
        "#           x_train=x_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           x_val=x_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           x_test=x_test,\n",
        "#           reg_y_train=reg_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           reg_y_val=reg_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train[int(i*ratio*total_values):int((i+1)*ratio*total_values)],\n",
        "#           rol_y_val=rol_y_val[int(i*ratio*total_values_val):int((i+1)*ratio*total_values_val)],\n",
        "#           rol_y_test=rol_y_test)\n",
        "\n",
        "# i = i + 1\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values)) + \" to \" + str(int((i+1)*ratio*total_values)))\n",
        "# print (\"Storing results for i=\" + str(i) + \" - \" + str(int(i*ratio*total_values_val)) + \" to \" + str(int((i+1)*ratio*total_values_val)))\n",
        "\n",
        "\n",
        "# np.savez(f'{DATA_PATH}dataTrainValTestSet5.npz',\n",
        "#           x_train=x_train[int(i*ratio*total_values):],\n",
        "#           x_val=x_val[int(i*ratio*total_values_val):],\n",
        "#           x_test=x_test,\n",
        "#           reg_y_train=reg_y_train[int(i*ratio*total_values):],\n",
        "#           reg_y_val=reg_y_val[int(i*ratio*total_values_val):],\n",
        "#           reg_y_test=reg_y_test,\n",
        "#           rol_y_train=rol_y_train[int(i*ratio*total_values):],\n",
        "#           rol_y_val=rol_y_val[int(i*ratio*total_values_val):],\n",
        "#           rol_y_test=rol_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_tPqwglN4yq",
        "outputId": "97074667-8da2-478a-980c-875c8c2a3a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file dataTrainValTest.npz:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTest.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "cats_train\n",
            "cats_val\n",
            "cats_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "x_train:  (255758, 2199)\n",
            "x_val:  (63940, 2199)\n",
            "x_test:  (79925, 2199)\n",
            "rol_y_train:  (255758, 781)\n",
            "rol_y_val:  (63940, 781)\n",
            "rol_y_test:  (79925, 781)\n",
            "y_train:  (255758, 4103)\n",
            "y_val:  (63940, 4103)\n",
            "reg_y_test:  (79925, 4103)\n",
            "Storing results for train - i=0 - 0 to 79924\n",
            "Storing results for test i=0 - 0 to 12788\n",
            "Storing results for i=1 - 79924 to 159849\n",
            "Storing results for i=1 - 12788 to 25576\n",
            "Storing results for i=2 - 159849 to 239773\n",
            "Storing results for i=2 - 25576 to 38364\n",
            "Storing results for i=3 - 239773 to 319698\n",
            "Storing results for i=3 - 38364 to 51152\n",
            "Storing results for i=4 - 319698 to 399623\n",
            "Storing results for i=4 - 51152 to 63940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "8a85x6FgvTDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Full dataset\n",
        "\n",
        "import gzip\n",
        "import pickle as pkl\n",
        "import gc\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTest.npz'\n",
        "\n",
        "print ('reading from saved file dataTrainValTest.npz: ', DATA_NPZ_FILE)\n",
        "data = np.load(DATA_NPZ_FILE)\n",
        "lst = data.files\n",
        "for item in lst:\n",
        "    print(item)\n",
        "\n",
        "print(\"done\")\n",
        "x_train_load = data['x_train']\n",
        "x_val_load = data['x_val']\n",
        "\n",
        "x_train = x_train_load\n",
        "x_val = x_val_load\n",
        "\n",
        "del x_train_load\n",
        "del x_val_load\n",
        "\n",
        "print('x_train: ' , x_train.shape)\n",
        "print('x_val: ', x_val.shape)\n",
        "\n",
        "reg_y_train = data['reg_y_train']\n",
        "reg_y_val = data['reg_y_val']\n",
        "\n",
        "y_train = reg_y_train\n",
        "y_val = reg_y_val\n",
        "\n",
        "print('y_train: ', y_train.shape)\n",
        "print('y_val: ', y_val.shape)\n",
        "\n",
        "del data\n",
        "del lst\n",
        "del reg_y_train\n",
        "del reg_y_val\n",
        "\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tuEO6OKGt2h",
        "outputId": "2dc6dfc7-8763-49ee-f6ee-372cbc6d7551"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file dataTrainValTest.npz:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTest.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "cats_train\n",
            "cats_val\n",
            "cats_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (179030, 2199)\n",
            "x_val:  (44758, 2199)\n",
            "y_train:  (179030, 4103)\n",
            "y_val:  (44758, 4103)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set 1"
      ],
      "metadata": {
        "id": "7cAOANIiVCYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet1.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxY7oQUQ0dJ",
        "outputId": "86b9bf1c-0e79-407c-bf3c-db470521afab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet1.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79924, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79924, 4103)\n",
            "y_val:  (12788, 4103)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bum_es22GhBV",
        "outputId": "ffabc8b5-3579-4bb0-949e-2345c771d678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "    word_index = pkl.load(f)\n",
        "    print(\"Got word index\")"
      ],
      "metadata": {
        "id": "uUKDLFA24P2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657026a9-524c-49dd-c004-f0f1234f3067"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got word index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)"
      ],
      "metadata": {
        "id": "U1opgDef4TUG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n"
      ],
      "metadata": {
        "id": "T1Tc_5mJ6m0S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()"
      ],
      "metadata": {
        "id": "2oLv0E_6-m2y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) , embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix], input_length=x_train.shape[1],\n",
        "                    trainable=False))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"BOTModelOriginalRegular-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=10)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, checkpoint])\n"
      ],
      "metadata": {
        "id": "fGX5EC--6JNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cecf51-5f2e-4ce5-f0d6-d6a3475b14e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6392/6394 [============================>.] - ETA: 0s - loss: 0.0197 - precision: 0.4076 - recall: 0.0416\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-01-0.02.h5\n",
            "6394/6394 [==============================] - 36s 5ms/step - loss: 0.0197 - precision: 0.4076 - recall: 0.0416 - val_loss: 0.0185 - val_precision: 0.5438 - val_recall: 0.0619\n",
            "Epoch 2/25\n",
            "6382/6394 [============================>.] - ETA: 0s - loss: 0.0184 - precision: 0.6089 - recall: 0.0428\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-02-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0184 - precision: 0.6089 - recall: 0.0428 - val_loss: 0.0184 - val_precision: 0.6380 - val_recall: 0.0386\n",
            "Epoch 3/25\n",
            "6389/6394 [============================>.] - ETA: 0s - loss: 0.0183 - precision: 0.6083 - recall: 0.0441\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-03-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0183 - precision: 0.6083 - recall: 0.0441 - val_loss: 0.0183 - val_precision: 0.6321 - val_recall: 0.0424\n",
            "Epoch 4/25\n",
            "6384/6394 [============================>.] - ETA: 0s - loss: 0.0183 - precision: 0.6073 - recall: 0.0452\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-04-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0183 - precision: 0.6073 - recall: 0.0452 - val_loss: 0.0182 - val_precision: 0.5536 - val_recall: 0.0602\n",
            "Epoch 5/25\n",
            "6389/6394 [============================>.] - ETA: 0s - loss: 0.0183 - precision: 0.6084 - recall: 0.0462\n",
            "Epoch 5: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-05-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0183 - precision: 0.6085 - recall: 0.0462 - val_loss: 0.0182 - val_precision: 0.6394 - val_recall: 0.0395\n",
            "Epoch 6/25\n",
            "6386/6394 [============================>.] - ETA: 0s - loss: 0.0182 - precision: 0.6095 - recall: 0.0465\n",
            "Epoch 6: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-06-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0182 - precision: 0.6095 - recall: 0.0465 - val_loss: 0.0182 - val_precision: 0.6186 - val_recall: 0.0483\n",
            "Epoch 7/25\n",
            "6388/6394 [============================>.] - ETA: 0s - loss: 0.0182 - precision: 0.6101 - recall: 0.0473\n",
            "Epoch 7: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-07-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0182 - precision: 0.6101 - recall: 0.0473 - val_loss: 0.0182 - val_precision: 0.6407 - val_recall: 0.0417\n",
            "Epoch 8/25\n",
            "6387/6394 [============================>.] - ETA: 0s - loss: 0.0182 - precision: 0.6124 - recall: 0.0474\n",
            "Epoch 8: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-08-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0182 - precision: 0.6125 - recall: 0.0474 - val_loss: 0.0181 - val_precision: 0.6342 - val_recall: 0.0457\n",
            "Epoch 9/25\n",
            "6387/6394 [============================>.] - ETA: 0s - loss: 0.0182 - precision: 0.6123 - recall: 0.0476\n",
            "Epoch 9: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-09-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0182 - precision: 0.6123 - recall: 0.0476 - val_loss: 0.0182 - val_precision: 0.6379 - val_recall: 0.0450\n",
            "Epoch 10/25\n",
            "6391/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6113 - recall: 0.0485\n",
            "Epoch 10: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-10-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0181 - precision: 0.6113 - recall: 0.0485 - val_loss: 0.0182 - val_precision: 0.6419 - val_recall: 0.0425\n",
            "Epoch 11/25\n",
            "6386/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6117 - recall: 0.0488\n",
            "Epoch 11: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-11-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0181 - precision: 0.6116 - recall: 0.0488 - val_loss: 0.0181 - val_precision: 0.6686 - val_recall: 0.0196\n",
            "Epoch 12/25\n",
            "6383/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6112 - recall: 0.0493\n",
            "Epoch 12: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-12-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0181 - precision: 0.6113 - recall: 0.0493 - val_loss: 0.0181 - val_precision: 0.6406 - val_recall: 0.0436\n",
            "Epoch 13/25\n",
            "6388/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6142 - recall: 0.0495\n",
            "Epoch 13: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-13-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0181 - precision: 0.6142 - recall: 0.0495 - val_loss: 0.0181 - val_precision: 0.5614 - val_recall: 0.0691\n",
            "Epoch 14/25\n",
            "6389/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6124 - recall: 0.0502\n",
            "Epoch 14: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-14-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0181 - precision: 0.6124 - recall: 0.0502 - val_loss: 0.0181 - val_precision: 0.6432 - val_recall: 0.0436\n",
            "Epoch 15/25\n",
            "6383/6394 [============================>.] - ETA: 0s - loss: 0.0181 - precision: 0.6144 - recall: 0.0502\n",
            "Epoch 15: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-15-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0181 - precision: 0.6143 - recall: 0.0502 - val_loss: 0.0181 - val_precision: 0.6337 - val_recall: 0.0466\n",
            "Epoch 16/25\n",
            "6389/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6129 - recall: 0.0510\n",
            "Epoch 16: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-16-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6129 - recall: 0.0510 - val_loss: 0.0180 - val_precision: 0.6369 - val_recall: 0.0458\n",
            "Epoch 17/25\n",
            "6383/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6157 - recall: 0.0505\n",
            "Epoch 17: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-17-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0180 - precision: 0.6157 - recall: 0.0505 - val_loss: 0.0181 - val_precision: 0.5935 - val_recall: 0.0573\n",
            "Epoch 18/25\n",
            "6383/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6160 - recall: 0.0509\n",
            "Epoch 18: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-18-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6160 - recall: 0.0509 - val_loss: 0.0180 - val_precision: 0.6427 - val_recall: 0.0473\n",
            "Epoch 19/25\n",
            "6393/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6162 - recall: 0.0512\n",
            "Epoch 19: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-19-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6162 - recall: 0.0512 - val_loss: 0.0180 - val_precision: 0.5721 - val_recall: 0.0653\n",
            "Epoch 20/25\n",
            "6389/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6172 - recall: 0.0513\n",
            "Epoch 20: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-20-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6172 - recall: 0.0513 - val_loss: 0.0180 - val_precision: 0.6317 - val_recall: 0.0482\n",
            "Epoch 21/25\n",
            "6394/6394 [==============================] - ETA: 0s - loss: 0.0180 - precision: 0.6157 - recall: 0.0521\n",
            "Epoch 21: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-21-0.02.h5\n",
            "6394/6394 [==============================] - 32s 5ms/step - loss: 0.0180 - precision: 0.6157 - recall: 0.0521 - val_loss: 0.0179 - val_precision: 0.6422 - val_recall: 0.0478\n",
            "Epoch 22/25\n",
            "6390/6394 [============================>.] - ETA: 0s - loss: 0.0180 - precision: 0.6162 - recall: 0.0520\n",
            "Epoch 22: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-22-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6162 - recall: 0.0520 - val_loss: 0.0180 - val_precision: 0.5978 - val_recall: 0.0592\n",
            "Epoch 23/25\n",
            "6390/6394 [============================>.] - ETA: 0s - loss: 0.0179 - precision: 0.6165 - recall: 0.0522\n",
            "Epoch 23: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-23-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0180 - precision: 0.6165 - recall: 0.0522 - val_loss: 0.0180 - val_precision: 0.6444 - val_recall: 0.0463\n",
            "Epoch 24/25\n",
            "6392/6394 [============================>.] - ETA: 0s - loss: 0.0179 - precision: 0.6171 - recall: 0.0524\n",
            "Epoch 24: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-24-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0179 - precision: 0.6171 - recall: 0.0524 - val_loss: 0.0180 - val_precision: 0.6393 - val_recall: 0.0488\n",
            "Epoch 25/25\n",
            "6392/6394 [============================>.] - ETA: 0s - loss: 0.0179 - precision: 0.6167 - recall: 0.0530\n",
            "Epoch 25: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/BOTModelOriginalRegular-25-0.02.h5\n",
            "6394/6394 [==============================] - 31s 5ms/step - loss: 0.0179 - precision: 0.6167 - recall: 0.0530 - val_loss: 0.0180 - val_precision: 0.6360 - val_recall: 0.0506\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc2f52f5dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'BOTModelRegular.h5')"
      ],
      "metadata": {
        "id": "mieTexec7XDq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) , embedding_matrix.shape[1],\n",
        "                    weights=[embedding_matrix], input_length=x_train.shape[1],\n",
        "                    trainable=False))\n",
        "model.add(Conv1D(250, 3, activation='relu'))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNNModelRegularPartialDataset-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=10)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoGYxmFVvMXA",
        "outputId": "7247b7eb-1d40-4907-aa60-4171cdc30a55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "5595/5595 [==============================] - ETA: 0s - loss: 0.0188 - precision: 0.3756 - recall: 0.0471\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-01-0.02.h5\n",
            "5595/5595 [==============================] - 188s 32ms/step - loss: 0.0188 - precision: 0.3756 - recall: 0.0471 - val_loss: 0.0178 - val_precision: 0.5897 - val_recall: 0.0674\n",
            "Epoch 2/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0175 - precision: 0.6313 - recall: 0.0658\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-02-0.02.h5\n",
            "5595/5595 [==============================] - 175s 31ms/step - loss: 0.0175 - precision: 0.6313 - recall: 0.0658 - val_loss: 0.0172 - val_precision: 0.6355 - val_recall: 0.0738\n",
            "Epoch 3/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0170 - precision: 0.6446 - recall: 0.0806\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-03-0.02.h5\n",
            "5595/5595 [==============================] - 174s 31ms/step - loss: 0.0170 - precision: 0.6446 - recall: 0.0806 - val_loss: 0.0168 - val_precision: 0.6397 - val_recall: 0.0930\n",
            "Epoch 4/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0166 - precision: 0.6546 - recall: 0.0918\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-04-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0166 - precision: 0.6546 - recall: 0.0918 - val_loss: 0.0165 - val_precision: 0.6659 - val_recall: 0.0901\n",
            "Epoch 5/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0164 - precision: 0.6615 - recall: 0.1000\n",
            "Epoch 5: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-05-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0164 - precision: 0.6615 - recall: 0.1000 - val_loss: 0.0163 - val_precision: 0.6669 - val_recall: 0.1001\n",
            "Epoch 6/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0161 - precision: 0.6695 - recall: 0.1073\n",
            "Epoch 6: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-06-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0161 - precision: 0.6695 - recall: 0.1073 - val_loss: 0.0161 - val_precision: 0.6756 - val_recall: 0.1030\n",
            "Epoch 7/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0159 - precision: 0.6758 - recall: 0.1135\n",
            "Epoch 7: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-07-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0159 - precision: 0.6758 - recall: 0.1135 - val_loss: 0.0160 - val_precision: 0.6679 - val_recall: 0.1128\n",
            "Epoch 8/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0158 - precision: 0.6829 - recall: 0.1192\n",
            "Epoch 8: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-08-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0158 - precision: 0.6829 - recall: 0.1192 - val_loss: 0.0159 - val_precision: 0.6631 - val_recall: 0.1238\n",
            "Epoch 9/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0156 - precision: 0.6883 - recall: 0.1246\n",
            "Epoch 9: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-09-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0156 - precision: 0.6883 - recall: 0.1245 - val_loss: 0.0157 - val_precision: 0.6587 - val_recall: 0.1326\n",
            "Epoch 10/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0155 - precision: 0.6937 - recall: 0.1294\n",
            "Epoch 10: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-10-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0155 - precision: 0.6936 - recall: 0.1294 - val_loss: 0.0157 - val_precision: 0.6794 - val_recall: 0.1291\n",
            "Epoch 11/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0154 - precision: 0.6986 - recall: 0.1340\n",
            "Epoch 11: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-11-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0154 - precision: 0.6986 - recall: 0.1340 - val_loss: 0.0156 - val_precision: 0.6664 - val_recall: 0.1425\n",
            "Epoch 12/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0153 - precision: 0.7025 - recall: 0.1384\n",
            "Epoch 12: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-12-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0153 - precision: 0.7025 - recall: 0.1384 - val_loss: 0.0155 - val_precision: 0.6888 - val_recall: 0.1345\n",
            "Epoch 13/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0152 - precision: 0.7064 - recall: 0.1421\n",
            "Epoch 13: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-13-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0152 - precision: 0.7064 - recall: 0.1421 - val_loss: 0.0155 - val_precision: 0.6840 - val_recall: 0.1436\n",
            "Epoch 14/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0151 - precision: 0.7096 - recall: 0.1459\n",
            "Epoch 14: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-14-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0151 - precision: 0.7096 - recall: 0.1459 - val_loss: 0.0153 - val_precision: 0.6920 - val_recall: 0.1471\n",
            "Epoch 15/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0150 - precision: 0.7126 - recall: 0.1493\n",
            "Epoch 15: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-15-0.02.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0150 - precision: 0.7126 - recall: 0.1493 - val_loss: 0.0153 - val_precision: 0.6878 - val_recall: 0.1511\n",
            "Epoch 16/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0149 - precision: 0.7157 - recall: 0.1528\n",
            "Epoch 16: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-16-0.01.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0149 - precision: 0.7157 - recall: 0.1528 - val_loss: 0.0152 - val_precision: 0.6987 - val_recall: 0.1453\n",
            "Epoch 17/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0149 - precision: 0.7179 - recall: 0.1556\n",
            "Epoch 17: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-17-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0149 - precision: 0.7179 - recall: 0.1556 - val_loss: 0.0152 - val_precision: 0.6920 - val_recall: 0.1558\n",
            "Epoch 18/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0148 - precision: 0.7207 - recall: 0.1589\n",
            "Epoch 18: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-18-0.01.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0148 - precision: 0.7207 - recall: 0.1589 - val_loss: 0.0152 - val_precision: 0.7109 - val_recall: 0.1484\n",
            "Epoch 19/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0147 - precision: 0.7230 - recall: 0.1616\n",
            "Epoch 19: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-19-0.01.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0147 - precision: 0.7230 - recall: 0.1616 - val_loss: 0.0151 - val_precision: 0.7009 - val_recall: 0.1573\n",
            "Epoch 20/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0147 - precision: 0.7246 - recall: 0.1641\n",
            "Epoch 20: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-20-0.01.h5\n",
            "5595/5595 [==============================] - 173s 31ms/step - loss: 0.0147 - precision: 0.7247 - recall: 0.1641 - val_loss: 0.0151 - val_precision: 0.7102 - val_recall: 0.1522\n",
            "Epoch 21/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0146 - precision: 0.7268 - recall: 0.1666\n",
            "Epoch 21: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-21-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0146 - precision: 0.7268 - recall: 0.1666 - val_loss: 0.0151 - val_precision: 0.6980 - val_recall: 0.1643\n",
            "Epoch 22/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0146 - precision: 0.7288 - recall: 0.1691\n",
            "Epoch 22: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-22-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0146 - precision: 0.7288 - recall: 0.1691 - val_loss: 0.0150 - val_precision: 0.7064 - val_recall: 0.1624\n",
            "Epoch 23/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0145 - precision: 0.7301 - recall: 0.1712\n",
            "Epoch 23: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-23-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0145 - precision: 0.7300 - recall: 0.1712 - val_loss: 0.0150 - val_precision: 0.7007 - val_recall: 0.1659\n",
            "Epoch 24/25\n",
            "5593/5595 [============================>.] - ETA: 0s - loss: 0.0145 - precision: 0.7309 - recall: 0.1735\n",
            "Epoch 24: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-24-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0145 - precision: 0.7309 - recall: 0.1735 - val_loss: 0.0149 - val_precision: 0.7165 - val_recall: 0.1651\n",
            "Epoch 25/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0144 - precision: 0.7328 - recall: 0.1755\n",
            "Epoch 25: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNModelRegularPartialDataset-25-0.01.h5\n",
            "5595/5595 [==============================] - 172s 31ms/step - loss: 0.0144 - precision: 0.7328 - recall: 0.1755 - val_loss: 0.0149 - val_precision: 0.7202 - val_recall: 0.1596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ad6711f90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNModelRegularPartialDataset.h5')"
      ],
      "metadata": {
        "id": "shTCUp-mvN3G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set 1 completed\n",
        "\n",
        "# from keras import metrics\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(len(word_index) , embedding_matrix.shape[1],\n",
        "#                     weights=[embedding_matrix], input_length=x_train.shape[1],\n",
        "#                     trainable=False))\n",
        "# model.add(Conv1D(250, 3, activation='relu'))\n",
        "# # model.add(ReLU())\n",
        "# model.add(GlobalAveragePooling1D())\n",
        "# model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[metrics.Precision(), metrics.Recall()], run_eagerly=True)\n",
        "\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# filepath = ORIGINAL_MODELS + \"CNNBaselineRegularSet1-{epoch:02d}-{loss:.2f}.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# # metrics = Metrics([x_val, y_val], '{}.log'.format(filename))\n",
        "# early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "# garbage_collection = GarbageCollectorCallback()\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=32, epochs=25,\n",
        "#           validation_data=[x_val, y_val],\n",
        "#           callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEE351WmKGad",
        "outputId": "80025c27-ba8f-43e1-c99e-9e80559e0703"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0197 - precision: 0.2571 - recall: 0.0447\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-01-0.02.h5\n",
            "2498/2498 [==============================] - 143s 54ms/step - loss: 0.0197 - precision: 0.2571 - recall: 0.0447 - val_loss: 0.0181 - val_precision: 0.5837 - val_recall: 0.0548\n",
            "Epoch 2/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0181 - precision: 0.6151 - recall: 0.0494\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-02-0.02.h5\n",
            "2498/2498 [==============================] - 133s 53ms/step - loss: 0.0181 - precision: 0.6151 - recall: 0.0494 - val_loss: 0.0179 - val_precision: 0.6177 - val_recall: 0.0543\n",
            "Epoch 3/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0178 - precision: 0.6270 - recall: 0.0580\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-03-0.02.h5\n",
            "2498/2498 [==============================] - 132s 53ms/step - loss: 0.0178 - precision: 0.6270 - recall: 0.0580 - val_loss: 0.0176 - val_precision: 0.6392 - val_recall: 0.0605\n",
            "Epoch 4/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0175 - precision: 0.6308 - recall: 0.0669\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-04-0.02.h5\n",
            "2498/2498 [==============================] - 132s 53ms/step - loss: 0.0175 - precision: 0.6308 - recall: 0.0669 - val_loss: 0.0175 - val_precision: 0.6367 - val_recall: 0.0701\n",
            "Epoch 5/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0172 - precision: 0.6372 - recall: 0.0734\n",
            "Epoch 5: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-05-0.02.h5\n",
            "2498/2498 [==============================] - 131s 52ms/step - loss: 0.0172 - precision: 0.6372 - recall: 0.0734 - val_loss: 0.0171 - val_precision: 0.6574 - val_recall: 0.0691\n",
            "Epoch 6/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0170 - precision: 0.6459 - recall: 0.0799\n",
            "Epoch 6: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-06-0.02.h5\n",
            "2498/2498 [==============================] - 131s 52ms/step - loss: 0.0170 - precision: 0.6459 - recall: 0.0799 - val_loss: 0.0169 - val_precision: 0.6361 - val_recall: 0.0873\n",
            "Epoch 7/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0168 - precision: 0.6513 - recall: 0.0863\n",
            "Epoch 7: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-07-0.02.h5\n",
            "2498/2498 [==============================] - 131s 52ms/step - loss: 0.0168 - precision: 0.6513 - recall: 0.0863 - val_loss: 0.0168 - val_precision: 0.6506 - val_recall: 0.0887\n",
            "Epoch 8/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0166 - precision: 0.6563 - recall: 0.0917\n",
            "Epoch 8: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-08-0.02.h5\n",
            "2498/2498 [==============================] - 131s 52ms/step - loss: 0.0166 - precision: 0.6563 - recall: 0.0917 - val_loss: 0.0167 - val_precision: 0.6454 - val_recall: 0.0965\n",
            "Epoch 9/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0165 - precision: 0.6601 - recall: 0.0961\n",
            "Epoch 9: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-09-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0165 - precision: 0.6601 - recall: 0.0961 - val_loss: 0.0165 - val_precision: 0.6445 - val_recall: 0.1014\n",
            "Epoch 10/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0163 - precision: 0.6643 - recall: 0.1003\n",
            "Epoch 10: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-10-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0163 - precision: 0.6643 - recall: 0.1003 - val_loss: 0.0164 - val_precision: 0.6581 - val_recall: 0.0989\n",
            "Epoch 11/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0162 - precision: 0.6667 - recall: 0.1042\n",
            "Epoch 11: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-11-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0162 - precision: 0.6666 - recall: 0.1042 - val_loss: 0.0163 - val_precision: 0.6526 - val_recall: 0.1049\n",
            "Epoch 12/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0161 - precision: 0.6704 - recall: 0.1077\n",
            "Epoch 12: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-12-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0161 - precision: 0.6704 - recall: 0.1077 - val_loss: 0.0163 - val_precision: 0.6647 - val_recall: 0.1050\n",
            "Epoch 13/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0160 - precision: 0.6741 - recall: 0.1114\n",
            "Epoch 13: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-13-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0160 - precision: 0.6741 - recall: 0.1114 - val_loss: 0.0162 - val_precision: 0.6560 - val_recall: 0.1108\n",
            "Epoch 14/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0159 - precision: 0.6785 - recall: 0.1147\n",
            "Epoch 14: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-14-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0159 - precision: 0.6785 - recall: 0.1147 - val_loss: 0.0161 - val_precision: 0.6490 - val_recall: 0.1170\n",
            "Epoch 15/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0158 - precision: 0.6809 - recall: 0.1179\n",
            "Epoch 15: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-15-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0158 - precision: 0.6809 - recall: 0.1179 - val_loss: 0.0161 - val_precision: 0.6550 - val_recall: 0.1182\n",
            "Epoch 16/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0157 - precision: 0.6851 - recall: 0.1209\n",
            "Epoch 16: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-16-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0157 - precision: 0.6851 - recall: 0.1209 - val_loss: 0.0160 - val_precision: 0.6577 - val_recall: 0.1196\n",
            "Epoch 17/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0156 - precision: 0.6870 - recall: 0.1239\n",
            "Epoch 17: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-17-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0156 - precision: 0.6870 - recall: 0.1239 - val_loss: 0.0159 - val_precision: 0.6631 - val_recall: 0.1195\n",
            "Epoch 18/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0155 - precision: 0.6910 - recall: 0.1266\n",
            "Epoch 18: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-18-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0155 - precision: 0.6910 - recall: 0.1266 - val_loss: 0.0159 - val_precision: 0.6599 - val_recall: 0.1274\n",
            "Epoch 19/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0155 - precision: 0.6930 - recall: 0.1294\n",
            "Epoch 19: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineRegularSet1-19-0.02.h5\n",
            "2498/2498 [==============================] - 130s 52ms/step - loss: 0.0155 - precision: 0.6930 - recall: 0.1294 - val_loss: 0.0159 - val_precision: 0.6684 - val_recall: 0.1236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f941a2ace90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNBaselineRegularSet1.h5')"
      ],
      "metadata": {
        "id": "WEdhC-TMKXQT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set2"
      ],
      "metadata": {
        "id": "L9RWQ_vuVUTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet2.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFzxTulkVzO7",
        "outputId": "8fc627e9-9d1f-4820-8791-8b8887479964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet2.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79925, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79925, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1592"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.callbacks import Callback\n",
        "# # from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.models import Sequential, load_model\n",
        "# from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras import backend as k"
      ],
      "metadata": {
        "id": "0ujIJmpHjy6o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class GarbageCollectorCallback(Callback):\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         gc.collect()\n",
        "#         k.clear_session()"
      ],
      "metadata": {
        "id": "HfgQot_rj1m5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# filepath = ORIGINAL_MODELS + \"CNNBaselineOriginalRegularSet2-{epoch:02d}-{loss:.2f}.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# model = load_model(ORIGINAL_MODELS + 'CNNBaselineRegularSet1.h5')\n",
        "\n",
        "# early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "# garbage_collection = GarbageCollectorCallback()\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=32, epochs=25,\n",
        "#           validation_data=[x_val, y_val],\n",
        "#           callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbpoijmJVTGM",
        "outputId": "d4240dbd-e0c6-4a6a-b8af-9ae6a672f336"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "   5/2498 [..............................] - ETA: 1:19 - loss: 0.0151 - precision: 0.6570 - recall: 0.1227WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.0154s). Check your callbacks.\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0158 - precision: 0.6772 - recall: 0.1222\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet2-01-0.02.h5\n",
            "2498/2498 [==============================] - 72s 29ms/step - loss: 0.0158 - precision: 0.6772 - recall: 0.1222 - val_loss: 0.0158 - val_precision: 0.6784 - val_recall: 0.1197\n",
            "Epoch 2/25\n",
            "2496/2498 [============================>.] - ETA: 0s - loss: 0.0157 - precision: 0.6860 - recall: 0.1241\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet2-02-0.02.h5\n",
            "2498/2498 [==============================] - 70s 28ms/step - loss: 0.0157 - precision: 0.6861 - recall: 0.1241 - val_loss: 0.0157 - val_precision: 0.6889 - val_recall: 0.1194\n",
            "Epoch 3/25\n",
            "2496/2498 [============================>.] - ETA: 0s - loss: 0.0156 - precision: 0.6914 - recall: 0.1267\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet2-03-0.02.h5\n",
            "2498/2498 [==============================] - 70s 28ms/step - loss: 0.0156 - precision: 0.6915 - recall: 0.1267 - val_loss: 0.0157 - val_precision: 0.6793 - val_recall: 0.1243\n",
            "Epoch 4/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0155 - precision: 0.6938 - recall: 0.1297\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet2-04-0.02.h5\n",
            "2498/2498 [==============================] - 71s 28ms/step - loss: 0.0155 - precision: 0.6938 - recall: 0.1297 - val_loss: 0.0156 - val_precision: 0.6830 - val_recall: 0.1261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f949f438690>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNBaselineRegularSet2.h5')"
      ],
      "metadata": {
        "id": "FcD0xFGhX4Q5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set3"
      ],
      "metadata": {
        "id": "-8cQtZWokcFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet3.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAsfQNhYkdnE",
        "outputId": "afb51914-3c3a-4f5b-c183-c8c15ef62c8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet3.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79924, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79924, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n"
      ],
      "metadata": {
        "id": "xCHfjMmekj0s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNNBaselineOriginalRegularSet3-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "\n",
        "model = load_model(ORIGINAL_MODELS + 'CNNBaselineRegularSet2.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=3)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyI624Zxknxj",
        "outputId": "d57dd8ef-86f9-419e-a00c-113c4307016b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2498/2498 [==============================] - ETA: 0s - loss: 0.0156 - precision: 0.6870 - recall: 0.1275\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet3-01-0.02.h5\n",
            "2498/2498 [==============================] - 79s 28ms/step - loss: 0.0156 - precision: 0.6870 - recall: 0.1275 - val_loss: 0.0156 - val_precision: 0.6869 - val_recall: 0.1306\n",
            "Epoch 2/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0155 - precision: 0.6941 - recall: 0.1297\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet3-02-0.02.h5\n",
            "2498/2498 [==============================] - 70s 28ms/step - loss: 0.0155 - precision: 0.6940 - recall: 0.1297 - val_loss: 0.0157 - val_precision: 0.6704 - val_recall: 0.1333\n",
            "Epoch 3/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0154 - precision: 0.6985 - recall: 0.1325\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet3-03-0.02.h5\n",
            "2498/2498 [==============================] - 70s 28ms/step - loss: 0.0154 - precision: 0.6986 - recall: 0.1325 - val_loss: 0.0156 - val_precision: 0.6932 - val_recall: 0.1303\n",
            "Epoch 4/25\n",
            "2497/2498 [============================>.] - ETA: 0s - loss: 0.0153 - precision: 0.7013 - recall: 0.1352\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet3-04-0.02.h5\n",
            "2498/2498 [==============================] - 71s 28ms/step - loss: 0.0153 - precision: 0.7013 - recall: 0.1352 - val_loss: 0.0155 - val_precision: 0.6937 - val_recall: 0.1319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3de2ea690>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNBaselineRegularSet3.h5')"
      ],
      "metadata": {
        "id": "yBbT_aWIkpRD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set4"
      ],
      "metadata": {
        "id": "RBxCYUOAkucT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet4.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIkfSh84k2FD",
        "outputId": "2bf401e5-c448-4568-ec79-05747f29ce85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet4.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (15985, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (15985, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1713"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n"
      ],
      "metadata": {
        "id": "hNWFznAQk0ni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNNBaselineOriginalRegularSet4-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "model = load_model(ORIGINAL_MODELS + 'CNNBaselineRegularSet3.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDj_VoQWkxZv",
        "outputId": "3c410fb3-b33a-4bb2-ef93-e5664a889d85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "  5/500 [..............................] - ETA: 17s - loss: 0.0157 - precision: 0.6608 - recall: 0.1112WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.0177s). Check your callbacks.\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.0155 - precision: 0.6861 - recall: 0.1333\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet4-01-0.02.h5\n",
            "500/500 [==============================] - 19s 38ms/step - loss: 0.0155 - precision: 0.6861 - recall: 0.1333 - val_loss: 0.0154 - val_precision: 0.6886 - val_recall: 0.1365\n",
            "Epoch 2/25\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.0153 - precision: 0.6957 - recall: 0.1347\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet4-02-0.02.h5\n",
            "500/500 [==============================] - 19s 37ms/step - loss: 0.0153 - precision: 0.6955 - recall: 0.1347 - val_loss: 0.0155 - val_precision: 0.6789 - val_recall: 0.1418\n",
            "Epoch 3/25\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.0152 - precision: 0.6995 - recall: 0.1366\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNNBaselineOriginalRegularSet4-03-0.02.h5\n",
            "500/500 [==============================] - 19s 37ms/step - loss: 0.0152 - precision: 0.6995 - recall: 0.1365 - val_loss: 0.0155 - val_precision: 0.6769 - val_recall: 0.1429\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2a00380d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNBaselineRegularSet4.h5')"
      ],
      "metadata": {
        "id": "t5aHHbd2kvm9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set5"
      ],
      "metadata": {
        "id": "HbjmlIlyk6fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet5.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dYA5-V3lAqR",
        "outputId": "87922d73-83b1-43db-e534-93b8c11e7c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet5.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (0, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (0, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n"
      ],
      "metadata": {
        "id": "buhs0xjAk_MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNNBaselineOriginalRegularSet5-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "model = load_model(ORIGINAL_MODELS + 'CNNBaselineRegularSet4.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "id": "tNZCBUmSk9uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNNBaselineRegularSet5.h5')"
      ],
      "metadata": {
        "id": "pZ8nuawXk7yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 3 layer"
      ],
      "metadata": {
        "id": "PaPhgVHAboSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set1"
      ],
      "metadata": {
        "id": "gB2LLhlltwQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet1.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fos3hd0it3Aa",
        "outputId": "a3b6eb56-5778-431b-9f51-9eea8d9c2f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet1.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79924, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79924, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n"
      ],
      "metadata": {
        "id": "UTeEZQhjt31s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNN3LayerOriginalRegularPartialSet-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "embedding_input = Input(shape=(x_train.shape[1],), dtype=np.int32)\n",
        "embedding_layer = Embedding(len(word_index), embedding_matrix.shape[1],\n",
        "                                weights=[embedding_matrix], input_length=x_train.shape[1],\n",
        "                                trainable=False)(embedding_input)\n",
        "x1 = Conv1D(250, 2, activation='relu')(embedding_layer)\n",
        "x1 = GlobalMaxPooling1D()(x1)\n",
        "x2 = Conv1D(250, 3, activation='relu')(embedding_layer)\n",
        "x2 = GlobalMaxPooling1D()(x2)\n",
        "x3 = Conv1D(250, 4, activation='relu')(embedding_layer)\n",
        "x3 = GlobalMaxPooling1D()(x3)\n",
        "x = concatenate([x1, x2, x3])\n",
        "output = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=[embedding_input], outputs=[output])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=10)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMSUZy_P7IGQ",
        "outputId": "aa213238-c7b9-4e45-fd5f-8440bf717aa1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "5595/5595 [==============================] - ETA: 0s - loss: 0.0177 - precision: 0.5599 - recall: 0.1357\n",
            "Epoch 1: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-01-0.02.h5\n",
            "5595/5595 [==============================] - 334s 58ms/step - loss: 0.0177 - precision: 0.5599 - recall: 0.1357 - val_loss: 0.0156 - val_precision: 0.6455 - val_recall: 0.1917\n",
            "Epoch 2/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0148 - precision: 0.6856 - recall: 0.2033\n",
            "Epoch 2: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-02-0.01.h5\n",
            "5595/5595 [==============================] - 323s 58ms/step - loss: 0.0148 - precision: 0.6856 - recall: 0.2033 - val_loss: 0.0143 - val_precision: 0.6913 - val_recall: 0.2283\n",
            "Epoch 3/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0138 - precision: 0.7168 - recall: 0.2373\n",
            "Epoch 3: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-03-0.01.h5\n",
            "5595/5595 [==============================] - 323s 58ms/step - loss: 0.0138 - precision: 0.7168 - recall: 0.2373 - val_loss: 0.0137 - val_precision: 0.7529 - val_recall: 0.2256\n",
            "Epoch 4/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0132 - precision: 0.7368 - recall: 0.2600\n",
            "Epoch 4: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-04-0.01.h5\n",
            "5595/5595 [==============================] - 323s 58ms/step - loss: 0.0132 - precision: 0.7368 - recall: 0.2600 - val_loss: 0.0134 - val_precision: 0.7267 - val_recall: 0.2674\n",
            "Epoch 5/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0128 - precision: 0.7494 - recall: 0.2756\n",
            "Epoch 5: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-05-0.01.h5\n",
            "5595/5595 [==============================] - 323s 58ms/step - loss: 0.0128 - precision: 0.7494 - recall: 0.2756 - val_loss: 0.0132 - val_precision: 0.7475 - val_recall: 0.2704\n",
            "Epoch 6/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0125 - precision: 0.7580 - recall: 0.2876\n",
            "Epoch 6: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-06-0.01.h5\n",
            "5595/5595 [==============================] - 321s 57ms/step - loss: 0.0125 - precision: 0.7580 - recall: 0.2876 - val_loss: 0.0131 - val_precision: 0.7756 - val_recall: 0.2638\n",
            "Epoch 7/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0123 - precision: 0.7635 - recall: 0.2961\n",
            "Epoch 7: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-07-0.01.h5\n",
            "5595/5595 [==============================] - 320s 57ms/step - loss: 0.0123 - precision: 0.7635 - recall: 0.2961 - val_loss: 0.0129 - val_precision: 0.7678 - val_recall: 0.2754\n",
            "Epoch 8/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0122 - precision: 0.7678 - recall: 0.3027\n",
            "Epoch 8: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-08-0.01.h5\n",
            "5595/5595 [==============================] - 320s 57ms/step - loss: 0.0122 - precision: 0.7678 - recall: 0.3027 - val_loss: 0.0129 - val_precision: 0.7593 - val_recall: 0.2842\n",
            "Epoch 9/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0121 - precision: 0.7716 - recall: 0.3077\n",
            "Epoch 9: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-09-0.01.h5\n",
            "5595/5595 [==============================] - 319s 57ms/step - loss: 0.0121 - precision: 0.7716 - recall: 0.3077 - val_loss: 0.0128 - val_precision: 0.7642 - val_recall: 0.2883\n",
            "Epoch 10/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0120 - precision: 0.7738 - recall: 0.3121\n",
            "Epoch 10: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-10-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0120 - precision: 0.7738 - recall: 0.3121 - val_loss: 0.0129 - val_precision: 0.7672 - val_recall: 0.2896\n",
            "Epoch 11/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0119 - precision: 0.7761 - recall: 0.3157\n",
            "Epoch 11: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-11-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0119 - precision: 0.7760 - recall: 0.3157 - val_loss: 0.0128 - val_precision: 0.7646 - val_recall: 0.2944\n",
            "Epoch 12/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0119 - precision: 0.7776 - recall: 0.3183\n",
            "Epoch 12: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-12-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0119 - precision: 0.7776 - recall: 0.3183 - val_loss: 0.0128 - val_precision: 0.7737 - val_recall: 0.2890\n",
            "Epoch 13/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0118 - precision: 0.7791 - recall: 0.3208\n",
            "Epoch 13: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-13-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0118 - precision: 0.7791 - recall: 0.3208 - val_loss: 0.0128 - val_precision: 0.7348 - val_recall: 0.3109\n",
            "Epoch 14/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0118 - precision: 0.7804 - recall: 0.3227\n",
            "Epoch 14: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-14-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0118 - precision: 0.7804 - recall: 0.3227 - val_loss: 0.0128 - val_precision: 0.7707 - val_recall: 0.2965\n",
            "Epoch 15/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0118 - precision: 0.7814 - recall: 0.3252\n",
            "Epoch 15: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-15-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0118 - precision: 0.7814 - recall: 0.3252 - val_loss: 0.0128 - val_precision: 0.7588 - val_recall: 0.3051\n",
            "Epoch 16/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0117 - precision: 0.7829 - recall: 0.3269\n",
            "Epoch 16: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-16-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0117 - precision: 0.7829 - recall: 0.3269 - val_loss: 0.0128 - val_precision: 0.7612 - val_recall: 0.3073\n",
            "Epoch 17/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0117 - precision: 0.7845 - recall: 0.3288\n",
            "Epoch 17: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-17-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0117 - precision: 0.7844 - recall: 0.3288 - val_loss: 0.0128 - val_precision: 0.7292 - val_recall: 0.3223\n",
            "Epoch 18/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0117 - precision: 0.7851 - recall: 0.3299\n",
            "Epoch 18: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-18-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0117 - precision: 0.7851 - recall: 0.3299 - val_loss: 0.0129 - val_precision: 0.7628 - val_recall: 0.3021\n",
            "Epoch 19/25\n",
            "5594/5595 [============================>.] - ETA: 0s - loss: 0.0117 - precision: 0.7861 - recall: 0.3311\n",
            "Epoch 19: saving model to drive/My Drive/CS598DLHProject/data/preprocessed_3004/originalModels/regular/CNN3LayerOriginalRegularPartialSet-19-0.01.h5\n",
            "5595/5595 [==============================] - 318s 57ms/step - loss: 0.0117 - precision: 0.7861 - recall: 0.3311 - val_loss: 0.0128 - val_precision: 0.7589 - val_recall: 0.3078\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f761e29ae10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNN3LayerOriginalRegularPartialSet.h5')"
      ],
      "metadata": {
        "id": "QUml7Djq7P1e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import keras\n",
        "# # from tensorflow.keras.callbacks import EarlyStopping\n",
        "# # from tensorflow.keras.models import Model\n",
        "# # from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# filepath = ORIGINAL_MODELS + \"CNN3LayerOriginalRegularSet1-{epoch:02d}-{loss:.2f}.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "# embedding_input = Input(shape=(x_train.shape[1],), dtype=np.int32)\n",
        "# embedding_layer = Embedding(len(word_index), embedding_matrix.shape[1],\n",
        "#                                 weights=[embedding_matrix], input_length=x_train.shape[1],\n",
        "#                                 trainable=False)(embedding_input)\n",
        "# x1 = Conv1D(250, 2, activation='relu')(embedding_layer)\n",
        "# x1 = GlobalMaxPooling1D()(x1)\n",
        "# x2 = Conv1D(250, 3, activation='relu')(embedding_layer)\n",
        "# x2 = GlobalMaxPooling1D()(x2)\n",
        "# x3 = Conv1D(250, 4, activation='relu')(embedding_layer)\n",
        "# x3 = GlobalMaxPooling1D()(x3)\n",
        "# x = concatenate([x1, x2, x3])\n",
        "# output = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
        "\n",
        "# model = Model(inputs=[embedding_input], outputs=[output])\n",
        "\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "\n",
        "# # metrics = Metrics([x_val, y_val], '{}.log'.format(filename))\n",
        "# early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=32, epochs=25,\n",
        "#           validation_data=[x_val, y_val],\n",
        "#           callbacks=[early_stopping, checkpoint])"
      ],
      "metadata": {
        "id": "JNWub6feRXeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52e95ec-a0ac-42a7-dc76-14032bcd2085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2498/2498 [==============================] - 203s 80ms/step - loss: 0.0191 - precision: 0.4627 - recall: 0.1092 - val_loss: 0.0160 - val_precision: 0.6763 - val_recall: 0.1504\n",
            "Epoch 2/25\n",
            "2498/2498 [==============================] - 199s 80ms/step - loss: 0.0148 - precision: 0.7100 - recall: 0.1934 - val_loss: 0.0141 - val_precision: 0.7493 - val_recall: 0.2180\n",
            "Epoch 3/25\n",
            "2498/2498 [==============================] - 198s 79ms/step - loss: 0.0133 - precision: 0.7488 - recall: 0.2577 - val_loss: 0.0134 - val_precision: 0.7467 - val_recall: 0.2610\n",
            "Epoch 4/25\n",
            "2498/2498 [==============================] - 199s 80ms/step - loss: 0.0124 - precision: 0.7679 - recall: 0.3000 - val_loss: 0.0132 - val_precision: 0.7425 - val_recall: 0.2880\n",
            "Epoch 5/25\n",
            "2498/2498 [==============================] - 199s 79ms/step - loss: 0.0117 - precision: 0.7795 - recall: 0.3306 - val_loss: 0.0131 - val_precision: 0.7495 - val_recall: 0.2989\n",
            "Epoch 6/25\n",
            "2498/2498 [==============================] - 199s 80ms/step - loss: 0.0112 - precision: 0.7897 - recall: 0.3550 - val_loss: 0.0133 - val_precision: 0.7459 - val_recall: 0.3050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7dc0008b10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNN3LayerRegularSet1.h5')"
      ],
      "metadata": {
        "id": "utdbJiXhMEyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Set2"
      ],
      "metadata": {
        "id": "Q31cVvqXt-hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet2.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW-WFq9UuMza",
        "outputId": "a60cffae-3b3f-4b27-e823-a9aa58b5c7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet2.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79925, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79925, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1443"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNN3LayerOriginalRegularSet2-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "model = load_model(DATA_PATH + 'CNN3LayerRegularSet1.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfoMPhtYuJrQ",
        "outputId": "12285587-8ed3-476c-ad72-280cc75a395f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2498/2498 [==============================] - 199s 80ms/step - loss: 0.0129 - precision: 0.7721 - recall: 0.2917 - val_loss: 0.0126 - val_precision: 0.7841 - val_recall: 0.2970\n",
            "Epoch 2/25\n",
            "2498/2498 [==============================] - 198s 79ms/step - loss: 0.0119 - precision: 0.7932 - recall: 0.3274 - val_loss: 0.0126 - val_precision: 0.7792 - val_recall: 0.3069\n",
            "Epoch 3/25\n",
            "2498/2498 [==============================] - 198s 79ms/step - loss: 0.0114 - precision: 0.8010 - recall: 0.3490 - val_loss: 0.0126 - val_precision: 0.7685 - val_recall: 0.3200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7dcb326990>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNN3LayerRegularSet2.h5')"
      ],
      "metadata": {
        "id": "CJfLSy_Nt_2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set3"
      ],
      "metadata": {
        "id": "OXpeqhBTutwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet3.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLWZXhlTuyqm",
        "outputId": "cd85694d-a13f-4789-b0f8-da3984fb2d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet3.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (79924, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (79924, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNN3LayerOriginalRegularSet3-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "model = load_model(DATA_PATH + 'CNN3LayerRegularSet2.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQ-NueWuwka",
        "outputId": "f470299a-ad86-4d68-f21c-60ab866726fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2498/2498 [==============================] - 319s 123ms/step - loss: 0.0125 - precision: 0.7830 - recall: 0.3063 - val_loss: 0.0125 - val_precision: 0.7915 - val_recall: 0.3007\n",
            "Epoch 2/25\n",
            "2498/2498 [==============================] - 311s 124ms/step - loss: 0.0117 - precision: 0.8021 - recall: 0.3368 - val_loss: 0.0125 - val_precision: 0.7796 - val_recall: 0.3143\n",
            "Epoch 3/25\n",
            "2498/2498 [==============================] - 311s 124ms/step - loss: 0.0112 - precision: 0.8078 - recall: 0.3536 - val_loss: 0.0126 - val_precision: 0.7547 - val_recall: 0.3311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9803ac310>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNN3LayerRegularSet3.h5')"
      ],
      "metadata": {
        "id": "ONAhR1WkuvOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set 4"
      ],
      "metadata": {
        "id": "ElAj3j1lu243"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gzip\n",
        "# import pickle as pkl\n",
        "# import gc\n",
        "\n",
        "# import numpy as np\n",
        "\n",
        "# DATA_DIR = mypath + \"/data/\"\n",
        "\n",
        "# DATA_PATH = DATA_DIR + \"preprocessed_3004/\"\n",
        "# ORIGINAL_MODELS = DATA_PATH + \"originalModels/regular/\"\n",
        "\n",
        "# DATA_NPZ_FILE = f'{DATA_PATH}dataTrainValTestSet4.npz'\n",
        "\n",
        "# print ('reading from saved file: ', DATA_NPZ_FILE)\n",
        "# data = np.load(DATA_NPZ_FILE)\n",
        "# lst = data.files\n",
        "# for item in lst:\n",
        "#     print(item)\n",
        "\n",
        "# print(\"done\")\n",
        "# x_train_load = data['x_train']\n",
        "# x_val_load = data['x_val']\n",
        "# # x_test = data['x_test']\n",
        "\n",
        "# x_train = x_train_load\n",
        "# x_val = x_val_load\n",
        "# # x_test = x_test\n",
        "\n",
        "# del x_train_load\n",
        "# del x_val_load\n",
        "\n",
        "# print('x_train: ' , x_train.shape)\n",
        "# print('x_val: ', x_val.shape)\n",
        "# # print('x_test: ', x_test.shape)\n",
        "\n",
        "# # rol_y_train = data['rol_y_train']\n",
        "# # rol_y_val = data['rol_y_val']\n",
        "# # rol_y_test = data['rol_y_test']\n",
        "\n",
        "# # print('rol_y_train: ', rol_y_train.shape)\n",
        "# # print('rol_y_val: ', rol_y_val.shape)\n",
        "# # print('rol_y_test: ', rol_y_test.shape)\n",
        "\n",
        "# # y_train = rol_y_train\n",
        "# # y_val = rol_y_val\n",
        "# # y_test = rol_y_test\n",
        "\n",
        "\n",
        "# reg_y_train = data['reg_y_train']\n",
        "# reg_y_val = data['reg_y_val']\n",
        "# # reg_y_test = data['reg_y_test']\n",
        "\n",
        "\n",
        "# y_train = reg_y_train\n",
        "# y_val = reg_y_val\n",
        "# # y_test = reg_y_test\n",
        "\n",
        "# print('y_train: ', y_train.shape)\n",
        "# print('y_val: ', y_val.shape)\n",
        "# # print('reg_y_test: ', reg_y_test.shape)\n",
        "\n",
        "# del data\n",
        "# del lst\n",
        "# del reg_y_train\n",
        "# del reg_y_val\n",
        "# # del reg_y_test\n",
        "\n",
        "\n",
        "# with open(DATA_PATH + 'row_index_dictionary.p', 'rb') as f:\n",
        "#     word_index = pkl.load(f)\n",
        "#     print(\"Got word index\")\n",
        "\n",
        "# embedding_matrix = np.load(DATA_PATH + 'embedding_matrix.p', allow_pickle=True)\n",
        "\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luBbjGIMu8bz",
        "outputId": "8ccd8ddc-5e91-4151-e37b-54c66e0d9b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from saved file:  drive/My Drive/CS598DLHProject/data/preprocessed_3004/dataTrainValTestSet4.npz\n",
            "x_train\n",
            "x_val\n",
            "x_test\n",
            "reg_y_train\n",
            "reg_y_val\n",
            "reg_y_test\n",
            "rol_y_train\n",
            "rol_y_val\n",
            "rol_y_test\n",
            "done\n",
            "x_train:  (15985, 2199)\n",
            "x_val:  (12788, 2199)\n",
            "y_train:  (15985, 4103)\n",
            "y_val:  (12788, 4103)\n",
            "Got word index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1627"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Conv1D, ReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as k\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Conv1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "class GarbageCollectorCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = ORIGINAL_MODELS + \"CNN3LayerOriginalRegularSet4-{epoch:02d}-{loss:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "\n",
        "model = load_model(DATA_PATH + 'CNN3LayerRegularSet3.h5')\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta=.0001, patience=2)\n",
        "garbage_collection = GarbageCollectorCallback()\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=32, epochs=25,\n",
        "          validation_data=[x_val, y_val],\n",
        "          callbacks=[early_stopping, garbage_collection, checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ4YwLvau6V6",
        "outputId": "2b750c30-7eb8-48ab-c435-891cee4092e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "500/500 [==============================] - 75s 150ms/step - loss: 0.0124 - precision: 0.7845 - recall: 0.3159 - val_loss: 0.0124 - val_precision: 0.7891 - val_recall: 0.3172\n",
            "Epoch 2/25\n",
            "500/500 [==============================] - 74s 147ms/step - loss: 0.0111 - precision: 0.8277 - recall: 0.3615 - val_loss: 0.0125 - val_precision: 0.7790 - val_recall: 0.3263\n",
            "Epoch 3/25\n",
            "500/500 [==============================] - 74s 147ms/step - loss: 0.0104 - precision: 0.8412 - recall: 0.3927 - val_loss: 0.0128 - val_precision: 0.7605 - val_recall: 0.3285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb980344ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(ORIGINAL_MODELS + 'CNN3LayerRegularSet4.h5')"
      ],
      "metadata": {
        "id": "yop_kB6Hu4cT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}