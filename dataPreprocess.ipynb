{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
      "0    1297         109   172335      1.0     40301\n",
      "1    1298         109   172335      2.0       486\n",
      "2    1299         109   172335      3.0     58281\n",
      "3    1300         109   172335      4.0      5855\n",
      "4    1301         109   172335      5.0      4254\n"
     ]
    }
   ],
   "source": [
    "df_diag = pd.DataFrame()\n",
    "temp = pd.read_csv('../data/DIAGNOSES_ICD.csv', iterator=True, chunksize=1000)\n",
    "df_diag = pd.concat(temp, ignore_index=True)\n",
    "print(df_diag.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
      "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
      "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
      "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
      "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1  Discharge summary      Report   NaN      NaN   \n",
      "2  Discharge summary      Report   NaN      NaN   \n",
      "3  Discharge summary      Report   NaN      NaN   \n",
      "4  Discharge summary      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
      "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
      "2  Admission Date:  [**2119-5-4**]              D...  \n",
      "3  Admission Date:  [**2124-7-21**]              ...  \n",
      "4  Admission Date:  [**2162-3-3**]              D...  \n"
     ]
    }
   ],
   "source": [
    "df_notes = pd.DataFrame()\n",
    "temp = pd.read_csv('../data/NOTEEVENTS.csv', iterator=True, chunksize=1000)\n",
    "df_notes = pd.concat(temp, ignore_index=True)\n",
    "print(df_notes.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2083180, 11)\n",
      "(651047, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_notes.shape)\n",
    "print(df_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14222, 1)\n",
      "   HADM_ID\n",
      "0   140784\n",
      "1   164853\n",
      "2   195632\n",
      "3   113323\n",
      "4   198214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Unique subject IDs with Diabetes\n",
    "# df_sub_id_diabetes = df_diag[df_diag['ICD9_CODE'].str.startswith(\"250\", na = False)]['SUBJECT_ID'].to_frame()\n",
    "df_sub_id_diabetes = df_diag[df_diag['ICD9_CODE'].str.startswith(\"250\", na = False)]['HADM_ID'].to_frame()\n",
    "\n",
    "\n",
    "df_sub_id_diabetes = df_sub_id_diabetes.reset_index(drop=True)\n",
    "df_sub_id_diabetes = df_sub_id_diabetes.drop_duplicates()\n",
    "print(df_sub_id_diabetes.shape)\n",
    "print(df_sub_id_diabetes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199964, 5)\n",
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
      "0    1523         117   140784      1.0      5715\n",
      "1    1524         117   140784      2.0      7895\n"
     ]
    }
   ],
   "source": [
    "# df_diag_diabetes = pd.merge(df_diag, df_sub_id_diabetes, on=['SUBJECT_ID'], how='inner')\n",
    "df_diag_diabetes = pd.merge(df_diag, df_sub_id_diabetes, on=['HADM_ID'], how='inner')\n",
    "\n",
    "print(df_diag_diabetes.shape)\n",
    "print(df_diag_diabetes.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406203, 11)\n",
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
      "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1               Echo      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  Admission Date:  [**2125-2-9**]              D...  \n",
      "1  PATIENT/TEST INFORMATION:\\nIndication: Aortic ...  \n"
     ]
    }
   ],
   "source": [
    "# df_notes_diabetes = pd.merge(df_notes, df_sub_id_diabetes, on=['SUBJECT_ID'], how='inner')\n",
    "df_notes_diabetes = pd.merge(df_notes, df_sub_id_diabetes, on=['HADM_ID'], how='inner')\n",
    "\n",
    "print(df_notes_diabetes.shape)\n",
    "print(df_notes_diabetes.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Admission Date      dddd d d                 D...\n",
       "1    PATIENT TEST INFORMATION \\nIndication  Aortic ...\n",
       "2    PATIENT TEST INFORMATION \\nIndication   Aortic...\n",
       "3    Sinus rhythm   Frequent atrial premature beats...\n",
       "4    Rhythm is most likely sinus rhythm with freque...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT'].replace(r\"[^\\w\\s']\", ' ', regex=True).replace('[\\d]', 'd',regex=True)\n",
    "# df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT']\n",
    "df_notes_diabetes['TEXT'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission date      dddd d d                 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59801</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient test information \\nindication  aortic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59802</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient test information \\nindication   aortic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105548</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECG</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sinus rhythm   frequent atrial premature beats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105549</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECG</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhythm is most likely sinus rhythm with freque...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
       "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
       "2   59802       28063  121936.0  2125-02-11       NaN       NaN   \n",
       "3  105548       28063  121936.0  2125-02-10       NaN       NaN   \n",
       "4  105549       28063  121936.0  2125-02-09       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1               Echo      Report   NaN      NaN   \n",
       "2               Echo      Report   NaN      NaN   \n",
       "3                ECG      Report   NaN      NaN   \n",
       "4                ECG      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  admission date      dddd d d                 d...  \n",
       "1  patient test information \\nindication  aortic ...  \n",
       "2  patient test information \\nindication   aortic...  \n",
       "3  sinus rhythm   frequent atrial premature beats...  \n",
       "4  rhythm is most likely sinus rhythm with freque...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT'].str.lower()\n",
    "\n",
    "df_notes_diabetes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
      "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
      "2   59802       28063  121936.0  2125-02-11       NaN       NaN   \n",
      "3  105548       28063  121936.0  2125-02-10       NaN       NaN   \n",
      "4  105549       28063  121936.0  2125-02-09       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1               Echo      Report   NaN      NaN   \n",
      "2               Echo      Report   NaN      NaN   \n",
      "3                ECG      Report   NaN      NaN   \n",
      "4                ECG      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \\\n",
      "0  admission date      dddd d d                 d...   \n",
      "1  patient test information \\nindication  aortic ...   \n",
      "2  patient test information \\nindication   aortic...   \n",
      "3  sinus rhythm   frequent atrial premature beats...   \n",
      "4  rhythm is most likely sinus rhythm with freque...   \n",
      "\n",
      "                                              TOKENS  \n",
      "0  [admission, date, dddd, d, d, discharge, date,...  \n",
      "1  [patient, test, information, indication, aorti...  \n",
      "2  [patient, test, information, indication, aorti...  \n",
      "3  [sinus, rhythm, frequent, atrial, premature, b...  \n",
      "4  [rhythm, is, most, likely, sinus, rhythm, with...  \n"
     ]
    }
   ],
   "source": [
    "df_notes_diabetes['TOKENS'] = df_notes_diabetes['TEXT'].str.split()\n",
    "print(df_notes_diabetes.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(df_notes_diabetes['TOKENS'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def wordListToFreqDict(wordFreqDict, wordlist):\n",
    "#     wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "#     tempDict = dict(list(zip(wordlist,wordfreq)))\n",
    "#     z = dict(Counter(wordFreqDict)+Counter(tempDict))\n",
    "#     return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wordListToFreqDict({}, df_notes_diabetes['TOKENS'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notes processed:  0\n",
      "notes processed:  10000\n",
      "notes processed:  20000\n",
      "notes processed:  30000\n",
      "notes processed:  40000\n",
      "notes processed:  50000\n",
      "notes processed:  60000\n",
      "notes processed:  70000\n",
      "notes processed:  80000\n",
      "notes processed:  90000\n",
      "notes processed:  100000\n",
      "notes processed:  110000\n",
      "notes processed:  120000\n",
      "notes processed:  130000\n",
      "notes processed:  140000\n",
      "notes processed:  150000\n",
      "notes processed:  160000\n",
      "notes processed:  170000\n",
      "notes processed:  180000\n",
      "notes processed:  190000\n",
      "notes processed:  200000\n",
      "notes processed:  210000\n",
      "notes processed:  220000\n",
      "notes processed:  230000\n",
      "notes processed:  240000\n",
      "notes processed:  250000\n",
      "notes processed:  260000\n",
      "notes processed:  270000\n",
      "notes processed:  280000\n",
      "notes processed:  290000\n",
      "notes processed:  300000\n",
      "notes processed:  310000\n",
      "notes processed:  320000\n",
      "notes processed:  330000\n",
      "notes processed:  340000\n",
      "notes processed:  350000\n",
      "notes processed:  360000\n",
      "notes processed:  370000\n",
      "notes processed:  380000\n",
      "notes processed:  390000\n",
      "notes processed:  400000\n"
     ]
    }
   ],
   "source": [
    "wordCorpus = {}\n",
    "word_freq_dict_list = []\n",
    "max_limit = 1000000\n",
    "\n",
    "for idx, tokens in enumerate(df_notes_diabetes['TOKENS']):\n",
    "  wordfreq = [tokens.count(p) for p in tokens]\n",
    "  tempDict = dict(list(zip(tokens,wordfreq)))\n",
    "  word_freq_dict_list.append(tempDict)\n",
    "  if idx % 10000 == 0:\n",
    "    print('notes processed: ', idx)\n",
    "  if idx == max_limit:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406203\n"
     ]
    }
   ],
   "source": [
    "# write to file - word frequency for each report\n",
    "\n",
    "# import pickle5 as pkl\n",
    "# pkl.dump( word_freq_dict_list, open( \"../data/wordFreq.p\", \"wb\" ) )\n",
    "print(len(word_freq_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406203\n"
     ]
    }
   ],
   "source": [
    "# read word frequency for each report\n",
    "word_freq_dict_list = []\n",
    "word_freq_dict_list = pkl.load(open( \"../data/wordFreq.p\",'rb'))\n",
    "print(len(word_freq_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303645 80841 20852 852 13\n"
     ]
    }
   ],
   "source": [
    "len_200 = 0\n",
    "len_500 = 0\n",
    "len_1000 = 0\n",
    "len_2000 = 0\n",
    "len_rest = 0\n",
    "\n",
    "for dict1 in word_freq_dict_list:\n",
    "  lent = len(dict1)\n",
    "  if lent > 0 and lent <= 200:\n",
    "    len_200 = len_200 + 1\n",
    "  elif lent > 200 and lent <= 500:\n",
    "    len_500 = len_500 + 1\n",
    "  elif lent > 500 and lent <= 1000:\n",
    "    len_1000 = len_1000 + 1\n",
    "  elif lent > 1000 and lent <= 2000:\n",
    "    len_2000 = len_2000 + 1\n",
    "  else:\n",
    "    len_rest = len_rest + 1\n",
    "\n",
    "print(len_200, len_500, len_1000, len_2000, len_rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "98664\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "136184\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "160116\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "163167\n"
     ]
    }
   ],
   "source": [
    "wordCorpus = {}\n",
    "\n",
    "def createWordCorpus(dictList, min_len, max_len, wordCorpus):\n",
    "  for idx, dict1 in enumerate(dictList):\n",
    "    lent = len(dict1)\n",
    "    if lent > min_len and lent <= max_len:\n",
    "      for key, value in dict1.items():\n",
    "        if key in wordCorpus:\n",
    "          wordCorpus[key] = wordCorpus[key] + dict1[key]\n",
    "        else:\n",
    "          wordCorpus[key] = dict1[key]\n",
    "  return wordCorpus\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 0, 200, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 200, 500, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 500, 1000, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 1000, 100000, wordCorpus)\n",
    "print(len(wordCorpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163167\n",
      "163167\n"
     ]
    }
   ],
   "source": [
    "print(len(wordCorpus))\n",
    "\n",
    "# write to file - word corpus with frequency - overall\n",
    "# pkl.dump( wordCorpus, open( \"../data/wordCorpus.p\", \"wb\" ) )\n",
    "\n",
    "# read from file - word corpus with frequency - overall\n",
    "\n",
    "# wordCorpus = pkl.load(open( \"../data/wordCorpus.p\",'rb'))\n",
    "# print(len(wordCorpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109863 53304\n"
     ]
    }
   ],
   "source": [
    "tokens_freq_lt_5 = {}\n",
    "tokens_freq_gt_5 = {}\n",
    "\n",
    "freq_limit = 5\n",
    "for key, value in wordCorpus.items():\n",
    "  if value < freq_limit:\n",
    "    tokens_freq_lt_5[key] = value\n",
    "  else:\n",
    "    tokens_freq_gt_5[key] = value\n",
    "\n",
    "print(len(tokens_freq_lt_5), len(tokens_freq_gt_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev\n",
    "\n",
    "def closestMatch(candidateToken, wordList):\n",
    "  min_dist = 99\n",
    "  similar_word = ''\n",
    "  for word in wordList:\n",
    "    dist = lev.distance(candidateToken, word)\n",
    "    if dist <= min_dist:\n",
    "      min_dist = dist\n",
    "      similar_word = word\n",
    "  return candidateToken, similar_word, min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inferolaterl inferolateral 1\n",
      "10000 exacerbatiopn exacerbation 1\n",
      "20000 ruffed cuffed 1\n",
      "30000 lsast llast 1\n",
      "40000 coupiuos copiuos 1\n",
      "50000 swishing wishing 1\n",
      "60000 cvvhad cvvhd 1\n",
      "70000 professed progessed 1\n",
      "80000 behelpful unhelpful 2\n",
      "90000 elevtive elective 1\n",
      "100000 normoreflexic hyporeflexic 4\n"
     ]
    }
   ],
   "source": [
    "# token mapping\n",
    "\n",
    "token_map = {}\n",
    "\n",
    "ii = 0\n",
    "for ct in tokens_freq_lt_5:\n",
    "  candidateToken, similar_word, min_dist = closestMatch(ct, tokens_freq_gt_5)\n",
    "  token_map[ct] = similar_word\n",
    "  if ii % 10000 == 0:\n",
    "    print(ii, candidateToken, similar_word, min_dist)\n",
    "  ii = ii + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109863\n",
      "109863\n",
      "exacerbation\n"
     ]
    }
   ],
   "source": [
    "print(len(token_map))\n",
    "\n",
    "# write to file - word corpus with frequency - overall\n",
    "# pkl.dump( token_map, open( \"../data/tokenMap.p\", \"wb\" ) )\n",
    "\n",
    "# read from file - word corpus with frequency - overall\n",
    "\n",
    "# token_map = pkl.load(open( \"../data/tokenMap.p\",'rb'))\n",
    "print(len(token_map))\n",
    "print(token_map['exacerbatiopn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tokens(tokens):\n",
    "  n_tokens = []\n",
    "  for token in tokens:\n",
    "    if token in tokens_freq_lt_5:\n",
    "      n_tokens.append(token_map[token])\n",
    "    else:\n",
    "      n_tokens.append(token)\n",
    "  return n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [admission, date, dddd, d, d, discharge, date,...\n",
      "1    [patient, test, information, indication, aorti...\n",
      "2    [patient, test, information, indication, aorti...\n",
      "3    [sinus, rhythm, frequent, atrial, premature, b...\n",
      "4    [rhythm, is, most, likely, sinus, rhythm, with...\n",
      "5    [atrial, fibrillation, intraventricular, condu...\n",
      "6    [probable, atrial, fibrillation, left, bundle,...\n",
      "7    [atrial, fibrillation, versus, wandering, atri...\n",
      "8    [probable, atrial, fibrillation, with, moderat...\n",
      "9    [most, likely, sinus, tachycardia, with, atria...\n",
      "Name: NTOKENS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_notes_diabetes['NTOKENS'] = \" \"\n",
    "\n",
    "# n_tokens = []\n",
    "# for idx, tokens in enumerate(df_notes_diabetes['TOKENS']):\n",
    "#   n_tokens = []\n",
    "#   for token in tokens:\n",
    "#     if token in tokens_freq_lt_5:\n",
    "#       n_tokens.append(token_map[token])\n",
    "#     else:\n",
    "#       n_tokens.append(token)\n",
    "\n",
    "\n",
    "#   df_notes_diabetes['NTOKENS'][idx] = n_tokens\n",
    "#   if idx % 10000 == 0:\n",
    "#     print(idx)\n",
    "#   if idx == 1000000:\n",
    "#     break\n",
    "\n",
    "df_notes_diabetes['NTOKENS'] = df_notes_diabetes['TOKENS'].apply(map_tokens)\n",
    "\n",
    "print(df_notes_diabetes['NTOKENS'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406193    [continued, sugar, came, up, to, ddd, md, awar...\n",
      "406194    [rn, progress, note, dddd, d, dd, dddam, neuro...\n",
      "406195    [rn, admit, and, progress, note, dddd, d, dd, ...\n",
      "406196    [pt, admitted, direct, to, unit, by, ambulance...\n",
      "406197    [msicu, nursing, progress, note, see, careview...\n",
      "406198    [s, micu, nursing, progress, note, pt, started...\n",
      "406199    [nursing, progress, notes, from, dddd, to, ddd...\n",
      "406200    [nursing, progress, note, dddd, dddd, please, ...\n",
      "406201    [dddd, dddd, rn, notes, micu, dd, y, o, f, pre...\n",
      "406202    [tsicu, progress, note, dddd, dddd, ddyo, fema...\n",
      "Name: NTOKENS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_notes_diabetes['NTOKENS'].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "# df_notes_diabetes.to_pickle(\"../data/notes_diabetes.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d114184c886ba29bffe38c6c6fdadc7ffef7ccc1b8a3a158ab752daf223c4cdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs598')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
