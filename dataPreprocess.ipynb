{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
      "0    1297         109   172335      1.0     40301\n",
      "1    1298         109   172335      2.0       486\n",
      "2    1299         109   172335      3.0     58281\n",
      "3    1300         109   172335      4.0      5855\n",
      "4    1301         109   172335      5.0      4254\n"
     ]
    }
   ],
   "source": [
    "df_diag = pd.DataFrame()\n",
    "temp = pd.read_csv('../data/DIAGNOSES_ICD.csv', iterator=True, chunksize=1000)\n",
    "df_diag = pd.concat(temp, ignore_index=True)\n",
    "print(df_diag.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     174       22532  167853.0  2151-08-04       NaN       NaN   \n",
      "1     175       13702  107527.0  2118-06-14       NaN       NaN   \n",
      "2     176       13702  167118.0  2119-05-25       NaN       NaN   \n",
      "3     177       13702  196489.0  2124-08-18       NaN       NaN   \n",
      "4     178       26880  135453.0  2162-03-25       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1  Discharge summary      Report   NaN      NaN   \n",
      "2  Discharge summary      Report   NaN      NaN   \n",
      "3  Discharge summary      Report   NaN      NaN   \n",
      "4  Discharge summary      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  Admission Date:  [**2151-7-16**]       Dischar...  \n",
      "1  Admission Date:  [**2118-6-2**]       Discharg...  \n",
      "2  Admission Date:  [**2119-5-4**]              D...  \n",
      "3  Admission Date:  [**2124-7-21**]              ...  \n",
      "4  Admission Date:  [**2162-3-3**]              D...  \n"
     ]
    }
   ],
   "source": [
    "df_notes = pd.DataFrame()\n",
    "temp = pd.read_csv('../data/NOTEEVENTS.csv', iterator=True, chunksize=1000)\n",
    "df_notes = pd.concat(temp, ignore_index=True)\n",
    "print(df_notes.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2083180, 11)\n",
      "(651047, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_notes.shape)\n",
    "print(df_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14222, 1)\n",
      "   HADM_ID\n",
      "0   140784\n",
      "1   164853\n",
      "2   195632\n",
      "3   113323\n",
      "4   198214\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Unique subject IDs with Diabetes\n",
    "# df_sub_id_diabetes = df_diag[df_diag['ICD9_CODE'].str.startswith(\"250\", na = False)]['SUBJECT_ID'].to_frame()\n",
    "df_sub_id_diabetes = df_diag[df_diag['ICD9_CODE'].str.startswith(\"250\", na = False)]['HADM_ID'].to_frame()\n",
    "\n",
    "\n",
    "df_sub_id_diabetes = df_sub_id_diabetes.reset_index(drop=True)\n",
    "df_sub_id_diabetes = df_sub_id_diabetes.drop_duplicates()\n",
    "print(df_sub_id_diabetes.shape)\n",
    "print(df_sub_id_diabetes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199964, 5)\n",
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
      "0    1523         117   140784      1.0      5715\n",
      "1    1524         117   140784      2.0      7895\n"
     ]
    }
   ],
   "source": [
    "# df_diag_diabetes = pd.merge(df_diag, df_sub_id_diabetes, on=['SUBJECT_ID'], how='inner')\n",
    "df_diag_diabetes = pd.merge(df_diag, df_sub_id_diabetes, on=['HADM_ID'], how='inner')\n",
    "\n",
    "print(df_diag_diabetes.shape)\n",
    "print(df_diag_diabetes.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(406203, 11)\n",
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
      "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1               Echo      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \n",
      "0  Admission Date:  [**2125-2-9**]              D...  \n",
      "1  PATIENT/TEST INFORMATION:\\nIndication: Aortic ...  \n"
     ]
    }
   ],
   "source": [
    "# df_notes_diabetes = pd.merge(df_notes, df_sub_id_diabetes, on=['SUBJECT_ID'], how='inner')\n",
    "df_notes_diabetes = pd.merge(df_notes, df_sub_id_diabetes, on=['HADM_ID'], how='inner')\n",
    "\n",
    "print(df_notes_diabetes.shape)\n",
    "print(df_notes_diabetes.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Admission Date      dddd d d                 D...\n",
       "1    PATIENT TEST INFORMATION \\nIndication  Aortic ...\n",
       "2    PATIENT TEST INFORMATION \\nIndication   Aortic...\n",
       "3    Sinus rhythm   Frequent atrial premature beats...\n",
       "4    Rhythm is most likely sinus rhythm with freque...\n",
       "Name: TEXT, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT'].replace(r\"[^\\w\\s']\", ' ', regex=True).replace('[\\d]', 'd',regex=True)\n",
    "# df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT']\n",
    "df_notes_diabetes['TEXT'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>admission date      dddd d d                 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59801</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient test information \\nindication  aortic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59802</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Echo</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient test information \\nindication   aortic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105548</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECG</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sinus rhythm   frequent atrial premature beats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105549</td>\n",
       "      <td>28063</td>\n",
       "      <td>121936.0</td>\n",
       "      <td>2125-02-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECG</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rhythm is most likely sinus rhythm with freque...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
       "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
       "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
       "2   59802       28063  121936.0  2125-02-11       NaN       NaN   \n",
       "3  105548       28063  121936.0  2125-02-10       NaN       NaN   \n",
       "4  105549       28063  121936.0  2125-02-09       NaN       NaN   \n",
       "\n",
       "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
       "0  Discharge summary      Report   NaN      NaN   \n",
       "1               Echo      Report   NaN      NaN   \n",
       "2               Echo      Report   NaN      NaN   \n",
       "3                ECG      Report   NaN      NaN   \n",
       "4                ECG      Report   NaN      NaN   \n",
       "\n",
       "                                                TEXT  \n",
       "0  admission date      dddd d d                 d...  \n",
       "1  patient test information \\nindication  aortic ...  \n",
       "2  patient test information \\nindication   aortic...  \n",
       "3  sinus rhythm   frequent atrial premature beats...  \n",
       "4  rhythm is most likely sinus rhythm with freque...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notes_diabetes['TEXT'] = df_notes_diabetes['TEXT'].str.lower()\n",
    "\n",
    "df_notes_diabetes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0     184       28063  121936.0  2125-02-16       NaN       NaN   \n",
      "1   59801       28063  121936.0  2125-02-12       NaN       NaN   \n",
      "2   59802       28063  121936.0  2125-02-11       NaN       NaN   \n",
      "3  105548       28063  121936.0  2125-02-10       NaN       NaN   \n",
      "4  105549       28063  121936.0  2125-02-09       NaN       NaN   \n",
      "\n",
      "            CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0  Discharge summary      Report   NaN      NaN   \n",
      "1               Echo      Report   NaN      NaN   \n",
      "2               Echo      Report   NaN      NaN   \n",
      "3                ECG      Report   NaN      NaN   \n",
      "4                ECG      Report   NaN      NaN   \n",
      "\n",
      "                                                TEXT  \\\n",
      "0  admission date      dddd d d                 d...   \n",
      "1  patient test information \\nindication  aortic ...   \n",
      "2  patient test information \\nindication   aortic...   \n",
      "3  sinus rhythm   frequent atrial premature beats...   \n",
      "4  rhythm is most likely sinus rhythm with freque...   \n",
      "\n",
      "                                              TOKENS  \n",
      "0  [admission, date, dddd, d, d, discharge, date,...  \n",
      "1  [patient, test, information, indication, aorti...  \n",
      "2  [patient, test, information, indication, aorti...  \n",
      "3  [sinus, rhythm, frequent, atrial, premature, b...  \n",
      "4  [rhythm, is, most, likely, sinus, rhythm, with...  \n"
     ]
    }
   ],
   "source": [
    "df_notes_diabetes['TOKENS'] = df_notes_diabetes['TEXT'].str.split()\n",
    "print(df_notes_diabetes.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(df_notes_diabetes['TOKENS'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def wordListToFreqDict(wordFreqDict, wordlist):\n",
    "#     wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "#     tempDict = dict(list(zip(wordlist,wordfreq)))\n",
    "#     z = dict(Counter(wordFreqDict)+Counter(tempDict))\n",
    "#     return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wordListToFreqDict({}, df_notes_diabetes['TOKENS'][7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notes processed:  0\n",
      "notes processed:  10000\n",
      "notes processed:  20000\n",
      "notes processed:  30000\n",
      "notes processed:  40000\n",
      "notes processed:  50000\n",
      "notes processed:  60000\n",
      "notes processed:  70000\n",
      "notes processed:  80000\n",
      "notes processed:  90000\n",
      "notes processed:  100000\n",
      "notes processed:  110000\n",
      "notes processed:  120000\n",
      "notes processed:  130000\n",
      "notes processed:  140000\n",
      "notes processed:  150000\n",
      "notes processed:  160000\n",
      "notes processed:  170000\n",
      "notes processed:  180000\n",
      "notes processed:  190000\n",
      "notes processed:  200000\n",
      "notes processed:  210000\n",
      "notes processed:  220000\n",
      "notes processed:  230000\n",
      "notes processed:  240000\n",
      "notes processed:  250000\n",
      "notes processed:  260000\n",
      "notes processed:  270000\n",
      "notes processed:  280000\n",
      "notes processed:  290000\n",
      "notes processed:  300000\n",
      "notes processed:  310000\n",
      "notes processed:  320000\n",
      "notes processed:  330000\n",
      "notes processed:  340000\n",
      "notes processed:  350000\n",
      "notes processed:  360000\n",
      "notes processed:  370000\n",
      "notes processed:  380000\n",
      "notes processed:  390000\n",
      "notes processed:  400000\n"
     ]
    }
   ],
   "source": [
    "wordCorpus = {}\n",
    "word_freq_dict_list = []\n",
    "max_limit = 1000000\n",
    "\n",
    "for idx, tokens in enumerate(df_notes_diabetes['TOKENS']):\n",
    "  wordfreq = [tokens.count(p) for p in tokens]\n",
    "  tempDict = dict(list(zip(tokens,wordfreq)))\n",
    "  word_freq_dict_list.append(tempDict)\n",
    "  if idx % 10000 == 0:\n",
    "    print('notes processed: ', idx)\n",
    "  if idx == max_limit:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406203\n"
     ]
    }
   ],
   "source": [
    "# write to file - word frequency for each report\n",
    "\n",
    "# import pickle5 as pkl\n",
    "# pkl.dump( word_freq_dict_list, open( \"../data/wordFreq.p\", \"wb\" ) )\n",
    "print(len(word_freq_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406203\n"
     ]
    }
   ],
   "source": [
    "# read word frequency for each report\n",
    "word_freq_dict_list = []\n",
    "word_freq_dict_list = pkl.load(open( \"../data/wordFreq.p\",'rb'))\n",
    "print(len(word_freq_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303645 80841 20852 852 13\n"
     ]
    }
   ],
   "source": [
    "len_200 = 0\n",
    "len_500 = 0\n",
    "len_1000 = 0\n",
    "len_2000 = 0\n",
    "len_rest = 0\n",
    "\n",
    "for dict1 in word_freq_dict_list:\n",
    "  lent = len(dict1)\n",
    "  if lent > 0 and lent <= 200:\n",
    "    len_200 = len_200 + 1\n",
    "  elif lent > 200 and lent <= 500:\n",
    "    len_500 = len_500 + 1\n",
    "  elif lent > 500 and lent <= 1000:\n",
    "    len_1000 = len_1000 + 1\n",
    "  elif lent > 1000 and lent <= 2000:\n",
    "    len_2000 = len_2000 + 1\n",
    "  else:\n",
    "    len_rest = len_rest + 1\n",
    "\n",
    "print(len_200, len_500, len_1000, len_2000, len_rest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "98664\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "136184\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "160116\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "163167\n"
     ]
    }
   ],
   "source": [
    "wordCorpus = {}\n",
    "\n",
    "def createWordCorpus(dictList, min_len, max_len, wordCorpus):\n",
    "  for idx, dict1 in enumerate(dictList):\n",
    "    lent = len(dict1)\n",
    "    if lent > min_len and lent <= max_len:\n",
    "      for key, value in dict1.items():\n",
    "        if key in wordCorpus:\n",
    "          wordCorpus[key] = wordCorpus[key] + dict1[key]\n",
    "        else:\n",
    "          wordCorpus[key] = dict1[key]\n",
    "  return wordCorpus\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 0, 200, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 200, 500, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 500, 1000, wordCorpus)\n",
    "print(len(wordCorpus))\n",
    "\n",
    "wordCorpus = createWordCorpus(word_freq_dict_list, 1000, 100000, wordCorpus)\n",
    "print(len(wordCorpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163167\n",
      "163167\n"
     ]
    }
   ],
   "source": [
    "print(len(wordCorpus))\n",
    "\n",
    "# write to file - word corpus with frequency - overall\n",
    "# pkl.dump( wordCorpus, open( \"../data/wordCorpus.p\", \"wb\" ) )\n",
    "\n",
    "# read from file - word corpus with frequency - overall\n",
    "\n",
    "# wordCorpus = pkl.load(open( \"../data/wordCorpus.p\",'rb'))\n",
    "# print(len(wordCorpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109863 53304\n"
     ]
    }
   ],
   "source": [
    "tokens_freq_lt_5 = {}\n",
    "tokens_freq_gt_5 = {}\n",
    "\n",
    "freq_limit = 5\n",
    "for key, value in wordCorpus.items():\n",
    "  if value < freq_limit:\n",
    "    tokens_freq_lt_5[key] = value\n",
    "  else:\n",
    "    tokens_freq_gt_5[key] = value\n",
    "\n",
    "print(len(tokens_freq_lt_5), len(tokens_freq_gt_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev\n",
    "\n",
    "def closestMatch(candidateToken, wordList):\n",
    "  min_dist = 99\n",
    "  similar_word = ''\n",
    "  for word in wordList:\n",
    "    dist = lev.distance(candidateToken, word)\n",
    "    if dist <= min_dist:\n",
    "      min_dist = dist\n",
    "      similar_word = word\n",
    "  return candidateToken, similar_word, min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inferolaterl inferolateral 1\n",
      "10000 exacerbatiopn exacerbation 1\n",
      "20000 ruffed cuffed 1\n",
      "30000 lsast llast 1\n",
      "40000 coupiuos copiuos 1\n",
      "50000 swishing wishing 1\n",
      "60000 cvvhad cvvhd 1\n",
      "70000 professed progessed 1\n",
      "80000 behelpful unhelpful 2\n",
      "90000 elevtive elective 1\n",
      "100000 normoreflexic hyporeflexic 4\n"
     ]
    }
   ],
   "source": [
    "# token mapping\n",
    "\n",
    "token_map = {}\n",
    "\n",
    "ii = 0\n",
    "for ct in tokens_freq_lt_5:\n",
    "  candidateToken, similar_word, min_dist = closestMatch(ct, tokens_freq_gt_5)\n",
    "  token_map[ct] = similar_word\n",
    "  if ii % 10000 == 0:\n",
    "    print(ii, candidateToken, similar_word, min_dist)\n",
    "  ii = ii + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109863\n",
      "109863\n",
      "exacerbation\n"
     ]
    }
   ],
   "source": [
    "print(len(token_map))\n",
    "\n",
    "# write to file - word corpus with frequency - overall\n",
    "# pkl.dump( token_map, open( \"../data/tokenMap.p\", \"wb\" ) )\n",
    "\n",
    "# read from file - word corpus with frequency - overall\n",
    "\n",
    "# token_map = pkl.load(open( \"../data/tokenMap.p\",'rb'))\n",
    "print(len(token_map))\n",
    "print(token_map['exacerbatiopn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_tokens(tokens):\n",
    "  n_tokens = []\n",
    "  for token in tokens:\n",
    "    if token in tokens_freq_lt_5:\n",
    "      n_tokens.append(token_map[token])\n",
    "    else:\n",
    "      n_tokens.append(token)\n",
    "  return n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [admission, date, dddd, d, d, discharge, date,...\n",
      "1    [patient, test, information, indication, aorti...\n",
      "2    [patient, test, information, indication, aorti...\n",
      "3    [sinus, rhythm, frequent, atrial, premature, b...\n",
      "4    [rhythm, is, most, likely, sinus, rhythm, with...\n",
      "5    [atrial, fibrillation, intraventricular, condu...\n",
      "6    [probable, atrial, fibrillation, left, bundle,...\n",
      "7    [atrial, fibrillation, versus, wandering, atri...\n",
      "8    [probable, atrial, fibrillation, with, moderat...\n",
      "9    [most, likely, sinus, tachycardia, with, atria...\n",
      "Name: NTOKENS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_notes_diabetes['NTOKENS'] = \" \"\n",
    "\n",
    "# n_tokens = []\n",
    "# for idx, tokens in enumerate(df_notes_diabetes['TOKENS']):\n",
    "#   n_tokens = []\n",
    "#   for token in tokens:\n",
    "#     if token in tokens_freq_lt_5:\n",
    "#       n_tokens.append(token_map[token])\n",
    "#     else:\n",
    "#       n_tokens.append(token)\n",
    "\n",
    "\n",
    "#   df_notes_diabetes['NTOKENS'][idx] = n_tokens\n",
    "#   if idx % 10000 == 0:\n",
    "#     print(idx)\n",
    "#   if idx == 1000000:\n",
    "#     break\n",
    "\n",
    "df_notes_diabetes['NTOKENS'] = df_notes_diabetes['TOKENS'].apply(map_tokens)\n",
    "\n",
    "print(df_notes_diabetes['NTOKENS'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406193    [continued, sugar, came, up, to, ddd, md, awar...\n",
      "406194    [rn, progress, note, dddd, d, dd, dddam, neuro...\n",
      "406195    [rn, admit, and, progress, note, dddd, d, dd, ...\n",
      "406196    [pt, admitted, direct, to, unit, by, ambulance...\n",
      "406197    [msicu, nursing, progress, note, see, careview...\n",
      "406198    [s, micu, nursing, progress, note, pt, started...\n",
      "406199    [nursing, progress, notes, from, dddd, to, ddd...\n",
      "406200    [nursing, progress, note, dddd, dddd, please, ...\n",
      "406201    [dddd, dddd, rn, notes, micu, dd, y, o, f, pre...\n",
      "406202    [tsicu, progress, note, dddd, dddd, ddyo, fema...\n",
      "Name: NTOKENS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_notes_diabetes['NTOKENS'].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "# df_notes_diabetes.to_pickle(\"../data/notes_diabetes.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes_diabetes['NTOKENS_LEN'] = df_notes_diabetes['NTOKENS'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399629, 14)\n",
      "(6574, 14)\n"
     ]
    }
   ],
   "source": [
    "# Filtering based on # tokens - GT 9 and LE 2200\n",
    "temp = df_notes_diabetes[(df_notes_diabetes['NTOKENS_LEN'] > 9) & (df_notes_diabetes['NTOKENS_LEN'] <= 2200)]\n",
    "print(temp.shape)\n",
    "\n",
    "temp1 = df_notes_diabetes[(df_notes_diabetes['NTOKENS_LEN'] <= 9) | (df_notes_diabetes['NTOKENS_LEN'] > 2200)]\n",
    "print(temp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE CHARTTIME STORETIME  \\\n",
      "0       184       28063  121936.0  2125-02-16       NaN       NaN   \n",
      "66      193       53151  150192.0  2182-11-03       NaN       NaN   \n",
      "86      195       22180  162436.0  2134-03-09       NaN       NaN   \n",
      "140     198       22180  190828.0  2139-12-04       NaN       NaN   \n",
      "148  105853       22180  133797.0  2139-12-26       NaN       NaN   \n",
      "\n",
      "              CATEGORY DESCRIPTION  CGID  ISERROR  \\\n",
      "0    Discharge summary      Report   NaN      NaN   \n",
      "66   Discharge summary      Report   NaN      NaN   \n",
      "86   Discharge summary      Report   NaN      NaN   \n",
      "140  Discharge summary      Report   NaN      NaN   \n",
      "148                ECG      Report   NaN      NaN   \n",
      "\n",
      "                                                  TEXT  \\\n",
      "0    admission date      dddd d d                 d...   \n",
      "66   admission date      dddd dd dd                ...   \n",
      "86   admission date      dddd d dd                 ...   \n",
      "140  admission date      dddd dd dd                ...   \n",
      "148           sinus rhythm   within normal limits \\n\\n   \n",
      "\n",
      "                                                TOKENS  \\\n",
      "0    [admission, date, dddd, d, d, discharge, date,...   \n",
      "66   [admission, date, dddd, dd, dd, discharge, dat...   \n",
      "86   [admission, date, dddd, d, dd, discharge, date...   \n",
      "140  [admission, date, dddd, dd, dd, discharge, dat...   \n",
      "148            [sinus, rhythm, within, normal, limits]   \n",
      "\n",
      "                                               NTOKENS  NTOKENS_LEN  \n",
      "0    [admission, date, dddd, d, d, discharge, date,...         2316  \n",
      "66   [admission, date, dddd, dd, dd, discharge, dat...         2355  \n",
      "86   [admission, date, dddd, d, dd, discharge, date...         3908  \n",
      "140  [admission, date, dddd, dd, dd, discharge, dat...         3126  \n",
      "148            [sinus, rhythm, within, normal, limits]            5  \n"
     ]
    }
   ],
   "source": [
    "print(temp1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE\n",
      "98550  317369       28063   121936      1.0     42843\n",
      "98551  317370       28063   121936      2.0     41071\n",
      "98552  317371       28063   121936      3.0      5990\n",
      "98553  317372       28063   121936      4.0      4275\n",
      "98554  317373       28063   121936      5.0      5849\n",
      "98555  317374       28063   121936      6.0      5070\n",
      "98556  317375       28063   121936      7.0      4280\n",
      "98557  317376       28063   121936      8.0      2724\n",
      "98558  317377       28063   121936      9.0      4019\n",
      "98559  317378       28063   121936     10.0     42731\n",
      "98560  317379       28063   121936     11.0      4148\n",
      "98561  317380       28063   121936     12.0     44020\n",
      "98562  317381       28063   121936     13.0     V4581\n",
      "98563  317382       28063   121936     14.0     25000\n",
      "98564  317383       28063   121936     15.0      5997\n",
      "98565  317384       28063   121936     16.0     E8796\n"
     ]
    }
   ],
   "source": [
    "print(df_diag_diabetes[(df_diag_diabetes['HADM_ID'] == 121936)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
      "0       184       28063  121936.0  2125-02-16                  NaN   \n",
      "1     59801       28063  121936.0  2125-02-12                  NaN   \n",
      "2     59802       28063  121936.0  2125-02-11                  NaN   \n",
      "3    105548       28063  121936.0  2125-02-10                  NaN   \n",
      "4    105549       28063  121936.0  2125-02-09                  NaN   \n",
      "5    105501       28063  121936.0  2125-02-16                  NaN   \n",
      "6    105502       28063  121936.0  2125-02-13                  NaN   \n",
      "7    105503       28063  121936.0  2125-02-12                  NaN   \n",
      "8    105504       28063  121936.0  2125-02-11                  NaN   \n",
      "9    105547       28063  121936.0  2125-02-10                  NaN   \n",
      "10   999237       28063  121936.0  2125-02-09  2125-02-09 21:01:00   \n",
      "11   999458       28063  121936.0  2125-02-11  2125-02-11 14:42:00   \n",
      "12   999719       28063  121936.0  2125-02-13  2125-02-13 08:04:00   \n",
      "13   999539       28063  121936.0  2125-02-12  2125-02-12 08:05:00   \n",
      "14   999414       28063  121936.0  2125-02-11  2125-02-11 08:05:00   \n",
      "15   999363       28063  121936.0  2125-02-10  2125-02-10 20:02:00   \n",
      "16  1629153       28063  121936.0  2125-02-11  2125-02-11 04:28:00   \n",
      "17  1629154       28063  121936.0  2125-02-11  2125-02-11 17:20:00   \n",
      "18  1629155       28063  121936.0  2125-02-11  2125-02-11 17:21:00   \n",
      "19  1629156       28063  121936.0  2125-02-12  2125-02-12 04:23:00   \n",
      "20  1629157       28063  121936.0  2125-02-12  2125-02-12 05:27:00   \n",
      "21  1629158       28063  121936.0  2125-02-12  2125-02-12 15:28:00   \n",
      "22  1629159       28063  121936.0  2125-02-13  2125-02-13 04:20:00   \n",
      "\n",
      "              STORETIME           CATEGORY                 DESCRIPTION  \\\n",
      "0                   NaN  Discharge summary                      Report   \n",
      "1                   NaN               Echo                      Report   \n",
      "2                   NaN               Echo                      Report   \n",
      "3                   NaN                ECG                      Report   \n",
      "4                   NaN                ECG                      Report   \n",
      "5                   NaN                ECG                      Report   \n",
      "6                   NaN                ECG                      Report   \n",
      "7                   NaN                ECG                      Report   \n",
      "8                   NaN                ECG                      Report   \n",
      "9                   NaN                ECG                      Report   \n",
      "10                  NaN          Radiology         CHEST (PORTABLE AP)   \n",
      "11                  NaN          Radiology  CHEST PORT. LINE PLACEMENT   \n",
      "12                  NaN          Radiology         CHEST (PORTABLE AP)   \n",
      "13                  NaN          Radiology         CHEST (PORTABLE AP)   \n",
      "14                  NaN          Radiology         CHEST (PORTABLE AP)   \n",
      "15                  NaN          Radiology         CHEST (PORTABLE AP)   \n",
      "16  2125-02-11 05:26:00      Nursing/other                      Report   \n",
      "17  2125-02-11 18:06:00      Nursing/other                      Report   \n",
      "18  2125-02-11 18:06:00      Nursing/other                      Report   \n",
      "19  2125-02-12 04:47:00      Nursing/other                      Report   \n",
      "20  2125-02-12 05:29:00      Nursing/other                      Report   \n",
      "21  2125-02-12 15:48:00      Nursing/other                      Report   \n",
      "22  2125-02-13 04:45:00      Nursing/other                      Report   \n",
      "\n",
      "       CGID  ISERROR                                               TEXT  \\\n",
      "0       NaN      NaN  admission date      dddd d d                 d...   \n",
      "1       NaN      NaN  patient test information \\nindication  aortic ...   \n",
      "2       NaN      NaN  patient test information \\nindication   aortic...   \n",
      "3       NaN      NaN  sinus rhythm   frequent atrial premature beats...   \n",
      "4       NaN      NaN  rhythm is most likely sinus rhythm with freque...   \n",
      "5       NaN      NaN  atrial fibrillation  intraventricular conducti...   \n",
      "6       NaN      NaN  probable atrial fibrillation   left bundle bra...   \n",
      "7       NaN      NaN  atrial fibrillation versus wandering atrial pa...   \n",
      "8       NaN      NaN  probable atrial fibrillation with moderate ven...   \n",
      "9       NaN      NaN  most likely sinus tachycardia with atrial ecto...   \n",
      "10      NaN      NaN     dddd d d    d dd pm\\n chest  portable ap   ...   \n",
      "11      NaN      NaN     dddd d dd    d dd pm\\n chest port  line pla...   \n",
      "12      NaN      NaN     dddd d dd    d dd am\\n chest  portable ap  ...   \n",
      "13      NaN      NaN     dddd d dd    d dd am\\n chest  portable ap  ...   \n",
      "14      NaN      NaN     dddd d dd    d dd am\\n chest  portable ap  ...   \n",
      "15      NaN      NaN     dddd d dd    d dd pm\\n chest  portable ap  ...   \n",
      "16  18654.0      NaN  ccu nursing admit note\\nplease see icu adm his...   \n",
      "17  16948.0      NaN  ccu npn dddd dddd\\ns   it hurts when i urinate...   \n",
      "18  16948.0      NaN  ccu npn dddd dddd\\n continued \\nsure areas \\n ...   \n",
      "19  18654.0      NaN  ccu npn dddd dddd\\ns   i guess i'm doing bette...   \n",
      "20  18654.0      NaN  ccu addenduem to above\\nbrief burst of afib no...   \n",
      "21  15654.0      NaN  dd yr old sp mi c decompensated heart failure ...   \n",
      "22  15218.0      NaN  ccu npn dp da\\ncv  hr dd dd's nsr  cont on po ...   \n",
      "\n",
      "                                               TOKENS  \\\n",
      "0   [admission, date, dddd, d, d, discharge, date,...   \n",
      "1   [patient, test, information, indication, aorti...   \n",
      "2   [patient, test, information, indication, aorti...   \n",
      "3   [sinus, rhythm, frequent, atrial, premature, b...   \n",
      "4   [rhythm, is, most, likely, sinus, rhythm, with...   \n",
      "5   [atrial, fibrillation, intraventricular, condu...   \n",
      "6   [probable, atrial, fibrillation, left, bundle,...   \n",
      "7   [atrial, fibrillation, versus, wandering, atri...   \n",
      "8   [probable, atrial, fibrillation, with, moderat...   \n",
      "9   [most, likely, sinus, tachycardia, with, atria...   \n",
      "10  [dddd, d, d, d, dd, pm, chest, portable, ap, c...   \n",
      "11  [dddd, d, dd, d, dd, pm, chest, port, line, pl...   \n",
      "12  [dddd, d, dd, d, dd, am, chest, portable, ap, ...   \n",
      "13  [dddd, d, dd, d, dd, am, chest, portable, ap, ...   \n",
      "14  [dddd, d, dd, d, dd, am, chest, portable, ap, ...   \n",
      "15  [dddd, d, dd, d, dd, pm, chest, portable, ap, ...   \n",
      "16  [ccu, nursing, admit, note, please, see, icu, ...   \n",
      "17  [ccu, npn, dddd, dddd, s, it, hurts, when, i, ...   \n",
      "18  [ccu, npn, dddd, dddd, continued, sure, areas,...   \n",
      "19  [ccu, npn, dddd, dddd, s, i, guess, i'm, doing...   \n",
      "20  [ccu, addenduem, to, above, brief, burst, of, ...   \n",
      "21  [dd, yr, old, sp, mi, c, decompensated, heart,...   \n",
      "22  [ccu, npn, dp, da, cv, hr, dd, dd's, nsr, cont...   \n",
      "\n",
      "                                              NTOKENS  NTOKENS_LEN  \n",
      "0   [admission, date, dddd, d, d, discharge, date,...         2316  \n",
      "1   [patient, test, information, indication, aorti...          428  \n",
      "2   [patient, test, information, indication, aorti...          306  \n",
      "3   [sinus, rhythm, frequent, atrial, premature, b...           18  \n",
      "4   [rhythm, is, most, likely, sinus, rhythm, with...           66  \n",
      "5   [atrial, fibrillation, intraventricular, condu...           53  \n",
      "6   [probable, atrial, fibrillation, left, bundle,...           16  \n",
      "7   [atrial, fibrillation, versus, wandering, atri...           20  \n",
      "8   [probable, atrial, fibrillation, with, moderat...           27  \n",
      "9   [most, likely, sinus, tachycardia, with, atria...           25  \n",
      "10  [dddd, d, d, d, dd, pm, chest, portable, ap, c...          180  \n",
      "11  [dddd, d, dd, d, dd, pm, chest, port, line, pl...          135  \n",
      "12  [dddd, d, dd, d, dd, am, chest, portable, ap, ...          166  \n",
      "13  [dddd, d, dd, d, dd, am, chest, portable, ap, ...          119  \n",
      "14  [dddd, d, dd, d, dd, am, chest, portable, ap, ...          135  \n",
      "15  [dddd, d, dd, d, dd, pm, chest, portable, ap, ...          111  \n",
      "16  [ccu, nursing, admit, note, please, see, icu, ...          481  \n",
      "17  [ccu, npn, dddd, dddd, s, it, hurts, when, i, ...          574  \n",
      "18  [ccu, npn, dddd, dddd, continued, sure, areas,...           19  \n",
      "19  [ccu, npn, dddd, dddd, s, i, guess, i'm, doing...          374  \n",
      "20  [ccu, addenduem, to, above, brief, burst, of, ...           18  \n",
      "21  [dd, yr, old, sp, mi, c, decompensated, heart,...          165  \n",
      "22  [ccu, npn, dp, da, cv, hr, dd, dd's, nsr, cont...          197  \n"
     ]
    }
   ],
   "source": [
    "print(df_notes_diabetes[(df_notes_diabetes['HADM_ID'] == 121936)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4103\n"
     ]
    }
   ],
   "source": [
    "print(len(df_diag_diabetes['ICD9_CODE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781\n"
     ]
    }
   ],
   "source": [
    "df_diag_diabetes['ICD9_CODE_ROLLED'] = df_diag_diabetes['ICD9_CODE'].apply(lambda x: x[0:3])\n",
    "print(len(df_diag_diabetes['ICD9_CODE_ROLLED'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.62789487249427\n"
     ]
    }
   ],
   "source": [
    "print(temp['NTOKENS_LEN'].sum() / len(temp['NTOKENS_LEN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d114184c886ba29bffe38c6c6fdadc7ffef7ccc1b8a3a158ab752daf223c4cdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs598')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
