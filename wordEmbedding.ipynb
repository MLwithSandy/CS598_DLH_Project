{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "DATA_DIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_diag_diabetes_hadm_ids.shape:    (14222,)\n",
      "df_diag_icd9.shape:                 (14222, 3)\n",
      "df_diag_icd9_rolled.shape:          (14222, 3)\n",
      "df_notes.shape:                     (399631, 8)\n",
      "notes_tokens_list.length:           53229\n"
     ]
    }
   ],
   "source": [
    "# load data from saved files - preprocessed data for notes and diagnosis codes\n",
    "\n",
    "df_diag_diabetes_hadm_ids = pkl.load(open(f'{DATA_DIR}diag_diabetes_hadm_ids.p','rb'))\n",
    "print('df_diag_diabetes_hadm_ids.shape:   ', df_diag_diabetes_hadm_ids.shape)\n",
    "\n",
    "df_diag_icd9 = pkl.load(open(f'{DATA_DIR}diag_icd9.p','rb'))\n",
    "print('df_diag_icd9.shape:                ', df_diag_icd9.shape)\n",
    "\n",
    "df_diag_icd9_rolled = pkl.load(open(f'{DATA_DIR}diag_icd9_rolled.p','rb'))\n",
    "print('df_diag_icd9_rolled.shape:         ', df_diag_icd9_rolled.shape)\n",
    "\n",
    "df_notes = pkl.load(open(f'{DATA_DIR}notes_final.p','rb'))\n",
    "print('df_notes.shape:                    ', df_notes.shape)\n",
    "\n",
    "notes_tokens_list = pkl.load(open(f'{DATA_DIR}notes_tokens_list.p','rb'))\n",
    "print('notes_tokens_list.length:          ', len(notes_tokens_list))\n",
    "\n",
    "icd9_unique_list = pkl.load(open(f'{DATA_DIR}diag_icd9_unique_list.p','rb'))\n",
    "print('icd9_unique_list.len:              ', len(icd9_unique_list))\n",
    "\n",
    "icd9_rolled_unique_list = pkl.load(open(f'{DATA_DIR}diag_icd9_rolled_unique_list.p','rb'))\n",
    "print('icd9_rolled_unique_list.len:       ', len(icd9_rolled_unique_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of used records              399631\n",
      "Num. of regular labels            4103\n",
      "Num. of rolled up labels          781\n",
      "Num. of unique tokens             53229\n",
      "Avg. num. of tokens per report    309.09424193818796\n"
     ]
    }
   ],
   "source": [
    "# Statistics for comparison with original paper statistics after preprocessing\n",
    "\n",
    "print('Num. of used records             ', df_notes.shape[0])\n",
    "print('Num. of regular labels           ',len(icd9_unique_list))\n",
    "print('Num. of rolled up labels         ',len(icd9_rolled_unique_list))\n",
    "print('Num. of unique tokens            ',len(notes_tokens_list))\n",
    "print('Avg. num. of tokens per report   ',df_notes['NTOKENS_LEN'].sum() / len(df_notes['NTOKENS_LEN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model, commented as model is already stored to file\n",
    "model = Word2Vec(df_notes['NTOKENS'].to_list(), min_count=1, vector_size=300, workers=4, sg=1)\n",
    "model.save('../data/word2vec_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=53278, vector_size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load('../data/word2vec_model.model')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty((len(df_notes['NTOKENS'])))\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 428, 300]) torch.Size([1, 306, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (428) must match the size of tensor b (306) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h1/bbx29rgs7297rs64yfyxr0kh0000gn/T/ipykernel_70128/2697737862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cs598/lib/python3.8/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (428) must match the size of tensor b (306) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for idx, notes in enumerate(df_notes['NTOKENS']):\n",
    "  if idx < 0:\n",
    "    continue\n",
    "  if idx % 1000 == 0:\n",
    "   print(idx)\n",
    "  t1 = model.wv[df_notes['NTOKENS'][idx]]\n",
    "  if idx == 0:\n",
    "    x = torch.from_numpy(t1).unsqueeze(0)\n",
    "  else:\n",
    "    t2 = torch.from_numpy(t1).unsqueeze(0)\n",
    "    print(x.shape, t2.shape)\n",
    "    x = pad_sequence([x, t2])\n",
    "    print(x.shape)\n",
    "\n",
    "  if idx == 10000:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d114184c886ba29bffe38c6c6fdadc7ffef7ccc1b8a3a158ab752daf223c4cdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs598')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
