{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import bz2\n",
    "\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "random.seed(3778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_diag_diabetes_hadm_ids.shape:    (14222,)\n",
      "df_diag_icd9.shape:                 (14222, 3)\n",
      "df_diag_icd9_rolled.shape:          (14222, 3)\n",
      "df_notes.shape:                     (399631, 8)\n",
      "notes_tokens_list.length:           53229\n",
      "icd9_unique_list.len:               4103\n",
      "icd9_rolled_unique_list.len:        781\n"
     ]
    }
   ],
   "source": [
    "# load data from saved files - preprocessed data for notes and diagnosis codes\n",
    "\n",
    "df_diag_diabetes_hadm_ids = pkl.load(open(f'{DATA_DIR}diag_diabetes_hadm_ids.p','rb'))\n",
    "print('df_diag_diabetes_hadm_ids.shape:   ', df_diag_diabetes_hadm_ids.shape)\n",
    "\n",
    "df_diag_icd9 = pkl.load(open(f'{DATA_DIR}diag_icd9.p','rb'))\n",
    "print('df_diag_icd9.shape:                ', df_diag_icd9.shape)\n",
    "\n",
    "df_diag_icd9_rolled = pkl.load(open(f'{DATA_DIR}diag_icd9_rolled.p','rb'))\n",
    "print('df_diag_icd9_rolled.shape:         ', df_diag_icd9_rolled.shape)\n",
    "\n",
    "df_notes = pkl.load(open(f'{DATA_DIR}notes_final.p','rb'))\n",
    "print('df_notes.shape:                    ', df_notes.shape)\n",
    "\n",
    "notes_tokens_list = pkl.load(open(f'{DATA_DIR}notes_tokens_list.p','rb'))\n",
    "print('notes_tokens_list.length:          ', len(notes_tokens_list))\n",
    "\n",
    "icd9_unique_list = pkl.load(open(f'{DATA_DIR}diag_icd9_unique_list.p','rb'))\n",
    "print('icd9_unique_list.len:              ', len(icd9_unique_list))\n",
    "\n",
    "icd9_rolled_unique_list = pkl.load(open(f'{DATA_DIR}diag_icd9_rolled_unique_list.p','rb'))\n",
    "print('icd9_rolled_unique_list.len:       ', len(icd9_rolled_unique_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of used records              399631\n",
      "Num. of regular labels            4103\n",
      "Num. of rolled up labels          781\n",
      "Num. of unique tokens             53229\n",
      "Avg. num. of tokens per report    309.09424193818796\n"
     ]
    }
   ],
   "source": [
    "# Statistics for comparison with original paper statistics after preprocessing\n",
    "\n",
    "print('Num. of used records             ', df_notes.shape[0])\n",
    "print('Num. of regular labels           ',len(icd9_unique_list))\n",
    "print('Num. of rolled up labels         ',len(icd9_rolled_unique_list))\n",
    "print('Num. of unique tokens            ',len(notes_tokens_list))\n",
    "print('Avg. num. of tokens per report   ',df_notes['NTOKENS_LEN'].sum() / len(df_notes['NTOKENS_LEN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_list len:  399631\n"
     ]
    }
   ],
   "source": [
    "# list of all notes\n",
    "text_list = df_notes['NTOKENS'].to_list()\n",
    "print('text_list len: ', len(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_notes_icd9.shape        :  (399631, 6)\n",
      "df_notes_icd9_rolled.shape :  (399631, 6)\n"
     ]
    }
   ],
   "source": [
    "df_notes_icd9 = pd.merge(df_notes, df_diag_icd9, on=['HADM_ID'], how='inner').drop(columns = ['TEXT', 'TOKENS', 'SUBJECT_ID', 'NTOKENS_LEN'])\n",
    "df_notes_icd9_rolled = pd.merge(df_notes, df_diag_icd9_rolled, on=['HADM_ID'], how='inner').drop(columns = ['TEXT', 'TOKENS', 'SUBJECT_ID', 'NTOKENS_LEN'])\n",
    "print('df_notes_icd9.shape        : ', df_notes_icd9.shape)\n",
    "print('df_notes_icd9_rolled.shape : ', df_notes_icd9_rolled.shape)\n",
    "\n",
    "# print(df_notes_icd9.head(2))\n",
    "# print(df_notes_icd9_rolled.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from saved model file:  Word2Vec(vocab=53203, vector_size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "w2v_model_file = f'{DATA_DIR}word2vec_model.model'\n",
    "\n",
    "if os.path.exists(w2v_model_file):\n",
    "  # read from saved file\n",
    "  model_w2v = Word2Vec.load(w2v_model_file)\n",
    "  print('read from saved model file: ', model_w2v)\n",
    "else:\n",
    "  # initialize Word2Vec\n",
    "  model_w2v = Word2Vec(min_count=1, vector_size=300, workers=4, sg=1, seed=3778)\n",
    "  print('model initialized: ',model_w2v)\n",
    "\n",
    "  model_w2v.build_vocab(text_list)\n",
    "  print('model vacab created: ',model_w2v)\n",
    "\n",
    "  # list of words not in word2vec vocab\n",
    "  dict1 = model_w2v.wv.index_to_key\n",
    "  dict2 = notes_tokens_list.keys()\n",
    "  print('tokens not in w2v vocab: ', dict2 - dict1 )\n",
    "\n",
    "  # Word2Vec model training - trained model saved\n",
    "  model_w2v.train(text_list, \n",
    "                  total_examples=model_w2v.corpus_count, \n",
    "                  epochs=model_w2v.epochs)\n",
    "  # Write to file \n",
    "  model_w2v.save(w2v_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_matrix.shape:  (53203, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create word embedding matrix\n",
    "embedding_matrix = model_w2v.wv[model_w2v.wv.index_to_key]\n",
    "print('embedding_matrix.shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_dict.length:  53203\n",
      "row_dict.length after padding:  53205\n"
     ]
    }
   ],
   "source": [
    "# Create dict for embedding matrix (word <-> row)\n",
    "row_dict=dict({word:idx for idx,word in enumerate(model_w2v.wv.index_to_key)})\n",
    "print('row_dict.length: ', len(row_dict))\n",
    "# Create and map unknown and padding tokens to null\n",
    "embedding_matrix = np.concatenate((embedding_matrix, np.zeros((2,300))), axis=0)\n",
    "row_dict['_unknown_'] = len(model_w2v.wv.index_to_key)\n",
    "row_dict['_padding_'] = len(model_w2v.wv.index_to_key) + 1\n",
    "print('row_dict.length after padding: ', len(row_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_dict.length after padding:  53205\n",
      "embedding_matrix.shape:  (53203, 300)\n"
     ]
    }
   ],
   "source": [
    "# save embedded matrix and row_dict to file\n",
    "# pkl.dump(row_dict, open(f'{DATA_DIR}row_index_dictionary.p', 'wb'))\n",
    "# pkl.dump(embedding_matrix, open(f'{DATA_DIR}embedded_matrix.p', 'wb'))\n",
    "\n",
    "# read from saved file\n",
    "row_dict = pkl.load(open(f'{DATA_DIR}row_index_dictionary.p', 'rb'))\n",
    "embedding_matrix = pkl.load(open(f'{DATA_DIR}embedded_matrix.p', 'rb'))\n",
    "print('row_dict.length after padding: ', len(row_dict))\n",
    "print('embedding_matrix.shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_token_to_index(tokens, row_dict):\n",
    "    return [row_dict.get(token, row_dict['_unknown_']) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 2200\n",
    "\n",
    "indexed_notes = (df_notes['NTOKENS']\n",
    "      .apply(convert_token_to_index, row_dict=row_dict)\n",
    "      .apply(lambda x: np.squeeze(pad_sequences([x], padding = 'post', truncating = 'post', \n",
    "      maxlen = MAX_LENGTH, value = row_dict['_padding_']))))\n",
    "      \n",
    "print(type(indexed_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.type:  <class 'numpy.ndarray'>\n",
      "X.shape:  (399631, 2200)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack(indexed_notes.to_list())\n",
    "print('X.type: ',type(X))\n",
    "print('X.shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_notes_icd9.shape:  (399631, 7)\n"
     ]
    }
   ],
   "source": [
    "df_notes_icd9['INDEXED_TOKENS'] = [x for x in X]\n",
    "print('df_notes_icd9.shape: ', df_notes_icd9.shape)\n",
    "# print(df_notes_icd9.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_notes_icd9_rolled.shape:  (399631, 7)\n"
     ]
    }
   ],
   "source": [
    "df_notes_icd9_rolled['INDEXED_TOKENS'] = [x for x in X]\n",
    "print('df_notes_icd9_rolled.shape: ', df_notes_icd9_rolled.shape)\n",
    "# print(df_notes_icd9_rolled.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 - 428 =  1772 , 2200 - 306 =  1894\n",
      "2200 - 428 =  1772 , 2200 - 306 =  1894\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "t1 = dict(Counter(df_notes_icd9['INDEXED_TOKENS'][0]))\n",
    "t2 = dict(Counter(df_notes_icd9['INDEXED_TOKENS'][1]))\n",
    "print('2200 - 428 = ', t1[53204],',', '2200 - 306 = ', t2[53204])\n",
    "\n",
    "t1 = dict(Counter(df_notes_icd9_rolled['INDEXED_TOKENS'][0]))\n",
    "t2 = dict(Counter(df_notes_icd9_rolled['INDEXED_TOKENS'][1]))\n",
    "print('2200 - 428 = ', t1[53204],',', '2200 - 306 = ', t2[53204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ICD9.type:  <class 'numpy.ndarray'>\n",
      "Y_ICD9.shape:  (399631, 4103)\n"
     ]
    }
   ],
   "source": [
    "Y_ICD9 = np.vstack(df_notes_icd9['ICD9_CODE_MLB'].to_numpy())\n",
    "print('Y_ICD9.type: ',type(Y_ICD9))\n",
    "print('Y_ICD9.shape: ', Y_ICD9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ICD9_ROLLED.type:  <class 'numpy.ndarray'>\n",
      "Y_ICD9_ROLLED.shape:  (399631, 781)\n"
     ]
    }
   ],
   "source": [
    "Y_ICD9_ROLLED = np.vstack(df_notes_icd9_rolled['ICD9_CODE_ROLLED_MLB'].to_numpy())\n",
    "print('Y_ICD9_ROLLED.type: ',type(Y_ICD9_ROLLED))\n",
    "print('Y_ICD9_ROLLED.shape: ', Y_ICD9_ROLLED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data and label to file\n",
    "pkl.dump(X, open(f'{DATA_DIR}X_NOTES_INDEXED.p', 'wb'))\n",
    "pkl.dump(Y_ICD9, open(f'{DATA_DIR}Y_ICD9.p', 'wb'))\n",
    "pkl.dump(Y_ICD9_ROLLED, open(f'{DATA_DIR}Y_ICD9_ROLLED.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.type:  <class 'numpy.ndarray'>\n",
      "X.shape:  (399631, 2200)\n",
      "Y_ICD9.type:  <class 'numpy.ndarray'>\n",
      "Y_ICD9.shape:  (399631, 4103)\n",
      "Y_ICD9_ROLLED.type:  <class 'numpy.ndarray'>\n",
      "Y_ICD9_ROLLED.shape:  (399631, 781)\n"
     ]
    }
   ],
   "source": [
    "# read from saved file\n",
    "\n",
    "X = pkl.load(open(f'{DATA_DIR}X_NOTES_INDEXED.p', 'rb'))\n",
    "print('X.type: ',type(X))\n",
    "print('X.shape: ', X.shape)\n",
    "\n",
    "Y_ICD9 = pkl.load(open(f'{DATA_DIR}Y_ICD9.p', 'rb'))\n",
    "print('Y_ICD9.type: ',type(Y_ICD9))\n",
    "print('Y_ICD9.shape: ', Y_ICD9.shape)\n",
    "\n",
    "Y_ICD9_ROLLED = pkl.load(open(f'{DATA_DIR}Y_ICD9_ROLLED.p', 'rb'))\n",
    "print('Y_ICD9_ROLLED.type: ',type(Y_ICD9_ROLLED))\n",
    "print('Y_ICD9_ROLLED.shape: ', Y_ICD9_ROLLED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data and label to file\n",
    "pkl.dump(X, bz2.BZ2File(f'{DATA_DIR}X_NOTES_INDEXED.bz2', 'wb'))\n",
    "print('X saved')\n",
    "# pkl.dump(Y_ICD9, bz2.BZ2File(f'{DATA_DIR}Y_ICD9.bz2', 'wb'))\n",
    "# print('Y_ICD9 saved')\n",
    "# pkl.dump(Y_ICD9_ROLLED, bz2.BZ2File(f'{DATA_DIR}Y_ICD9_ROLLED.bz2', 'wb'))\n",
    "# print('Y_ICD9 saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_ICD9_ROLLED.type:  <class 'numpy.ndarray'>\n",
      "Y_ICD9_ROLLED.shape:  (399631, 781)\n"
     ]
    }
   ],
   "source": [
    "Y_ICD9_ROLLED = pkl.load(bz2.BZ2File(f'{DATA_DIR}Y_ICD9_ROLLED.bz2', 'rb'))\n",
    "print('Y_ICD9_ROLLED.type: ',type(Y_ICD9_ROLLED))\n",
    "print('Y_ICD9_ROLLED.shape: ', Y_ICD9_ROLLED.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d114184c886ba29bffe38c6c6fdadc7ffef7ccc1b8a3a158ab752daf223c4cdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs598')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
